{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d5c1ea1-2c2e-4b35-87e2-182b42bfb373",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78fea065-9918-41e6-bd44-a1febeccde39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1133d0f90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"mps\")\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413e03fb-0750-4ae7-8270-d8f5991f4101",
   "metadata": {},
   "source": [
    "# 1. toy data (sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97ca1277-5724-4b7f-9253-20f453485b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"this movie is great and excellent\",\n",
    "    \"fantastic film wonderful direction\",\n",
    "    \"good plot amazing soundtrack\",\n",
    "    \"touching story strong performances\",\n",
    "    \"brilliant engaging narrative\",\n",
    "    \"bad pacing awful movie\",\n",
    "    \"boring film dull characters\",\n",
    "    \"terrible editing horrible dialogue\",\n",
    "    \"predictable script poor scenes\",\n",
    "    \"unwatchable messy scenes weak plot\",\n",
    "]\n",
    "labels = np.array([1,1,1,1,1, 0,0,0,0,0], dtype=np.int64)  # 1=POSITIVE, 0=NEGATIVE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75394d2c-6b4b-4889-89d1-54cbe085da44",
   "metadata": {},
   "source": [
    "# 2. Tokenization & Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45ae16c5-3ed8-4515-b07d-2ffe1a74f4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tok(s: str) -> List[str]:\n",
    "    return re.findall(r\"[a-z]+\", s.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1053e7d0-0477-42fe-8659-9bae6e9572ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD, UNK = \"<pad>\", \"<unk>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f87050db-2bde-4755-90e9-b1b82047f79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(texts: List[str], min_freq=1) -> Tuple[Dict[str, int], Dict[int, str]]:\n",
    "    count = Counter(t for s in texts for t in tok(s))\n",
    "    itos = [PAD, UNK] + [w for w, f in count.items() if f >= min_freq]\n",
    "    stoi = {s:i for i, s in enumerate(itos)}\n",
    "    return stoi, {i:w for w, i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c63bf3d0-8f3c-411b-9018-9cf9e0147dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi, itos = build_vocab(corpus, min_freq=1)\n",
    "pad_id, unk_id = stoi[PAD], stoi[UNK]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6272bd2a-3b94-4a4f-8005-e979a9b321ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(s: str) -> torch.Tensor:\n",
    "    ids = [stoi.get(w, unk_id) for w in tok(s)]\n",
    "    return torch.tensor(ids, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50aa809f-6c3b-470f-87a6-3790f6bb6638",
   "metadata": {},
   "source": [
    "# 3. Load Pretrained embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5d458e-492d-45d1-ad26-425b25140d65",
   "metadata": {},
   "source": [
    "if embedding exists in keyed_vector, pretrained one, then use pretrained, otherwise stay normalized initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a72b6af5-ee9a-4d88-9c10-8814d0b1ac43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_embedding_matrix(stoi: Dict[str,int], dim: int,\n",
    "                           keyed_vectors=None, freeze: bool=True) -> Tuple[nn.Embedding, int]:\n",
    "    \"\"\"\n",
    "    keyed_vectors: gensim KeyedVectors-like object (optional). Must expose:\n",
    "      - .key_to_index dict (word->idx), .vector_size, and __getitem__(word)->np.ndarray\n",
    "    \"\"\"\n",
    "    V = len(stoi)\n",
    "    W = np.random.normal(scale=0.01, size=(V, dim)).astype(np.float32)\n",
    "    W[pad_id] = 0.0\n",
    "\n",
    "    if keyed_vectors is not None:\n",
    "        if getattr(keyed_vectors, \"vector_size\", dim) != dim:\n",
    "            print(f\"[Emb] Dim mismatch: kv={keyed_vectors.vector_size}, requested={dim}. Using random init.\")\n",
    "        else:\n",
    "            hit = 0\n",
    "            for w, i in stoi.items():\n",
    "                if w in getattr(keyed_vectors, \"key_to_index\", {}):\n",
    "                    W[i] = keyed_vectors[w]\n",
    "                    hit += 1\n",
    "\n",
    "            print(f\"[Emb] Loaded {hit} / {V} pretrained vectors\")\n",
    "\n",
    "    emb = nn.Embedding(V, dim, padding_idx=pad_id)\n",
    "    emb.weight.data.copy_(torch.from_numpy(W))\n",
    "    emb.weight.requires_grad = not freeze\n",
    "    return emb, V\n",
    "\n",
    "\n",
    "kv = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144b767d-5e18-4cf5-ac0e-126dc5231c1a",
   "metadata": {},
   "source": [
    "# 4. Dataset / DataLoader with padding & lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80c7beb0-2953-4bba-bb50-4fb25f69f311",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClsDataset(Dataset):\n",
    "    def __init__(self, texts: List[str], lables: np.ndarray):\n",
    "        self.texts = texts\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        ids = encode(self.texts[i])\n",
    "        return ids, len(ids), self.labels[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce276c78-c3ed-4e54-888c-6d38afb8f23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    #batch: list of (ids, length, label)\n",
    "    ids, lens, ys = zip(*batch)\n",
    "    lens = torch.tensor(lens, dtype=torch.long)\n",
    "    padded = pad_sequence(ids, batch_first=True, padding_value=pad_id) # [B, T] batch_first is put batch size in first dimension\n",
    "    ys = torch.stack(ys)\n",
    "    #sort by length desc for pack_padded_sequence\n",
    "    lens, sort_idx = lens.sort(descending=True)\n",
    "    padded = padded.index_select(0, sort_idx)\n",
    "    ys = ys.index_select(0, sort_idx)\n",
    "    return padded, lens, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b71f03f6-d7ba-4f23-971b-ea1b09b5088b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split train/valid\n",
    "idx = np.arange(len(corpus))\n",
    "np.random.shuffle(idx)\n",
    "split = int(0.8 * len(idx))\n",
    "tr_idx, va_idx = idx[:split], idx[split:]\n",
    "train_ds = TextClsDataset([corpus[i] for i in tr_idx], labels[tr_idx])\n",
    "valid_ds = TextClsDataset([corpus[i] for i in va_idx], labels[va_idx])\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
    "#eg batch_size=4, DataLoader will pick batch_indices = [i1, i2, i3, i4]\n",
    "#for every i, use train_ds.__getitem__(i) to get 4 [(ids, len(ids), labels[i])]\n",
    "#then the collate_fn put those into a list as a batch\n",
    "#each time during training loop using DataLoader, will get returned value from the collate_fn on a batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75c18f9-5f50-44b5-9e6e-8a4650475e02",
   "metadata": {},
   "source": [
    "# 5. RNN classifier (supports LSTM/GRU, uni/bi-directional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34d209de-f4a6-42bc-8f96-5693fbfdad30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNClassifier(nn.Module):\n",
    "    def __init__(self, emb: nn.Embedding, hidden: int = 64,\n",
    "                 rnn_type: str = \"lstm\", bidirectional: bool = False,\n",
    "                 num_layers: int = 1, dropout: float = 0.0, num_classes: int = 2):\n",
    "        super().__init__()\n",
    "        self.emb = emb\n",
    "        self.embed_dim = emb.embedding_dim\n",
    "        self.hidden = hidden\n",
    "        self.bidirectional = bidirectional\n",
    "        self.num_dirs = 2 if bidirectional else 1\n",
    "        self.rnn_type = rnn_type.lower()\n",
    "        rnn_cls = nn.LSTM if self.rnn_type == \"lstm\" else nn.GRU\n",
    "\n",
    "        self.rnn = rnn_cls(\n",
    "            input_size=self.embed_dim, #word vector size dimension\n",
    "            hidden_size=hidden, #H RNN hidden state dimension H\n",
    "            num_layers=num_layers, #number of RNN stacking layers\n",
    "            dropout=dropout if num_layers > 1 else 0.0, #only if only num_layers>1 use dropout between layers\n",
    "            bidirectional=bidirectional,\n",
    "            batch_first=True, #shape will be [B, T, *]\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden * self.num_dirs, num_classes)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        #x: [B, T] int otkens\n",
    "        #lengths: [B]\n",
    "        emb = self.emb(x) #[B, T, D]\n",
    "        packed = pack_padded_sequence(emb, lengths.cpu(), batch_first=True, enforce_sorted=True)\n",
    "        out_packed, h = self.rnn(packed)\n",
    "\n",
    "        if self.rnn_type == \"lstm\":\n",
    "            h_n = h[0]\n",
    "        else:\n",
    "            h_n = h\n",
    "\n",
    "        last = torch.cat([h_n[-1]] if self.num_dirs == 1 else [h_n[-2], h_n[-1]], dim=-1)\n",
    "        logits = self.fc(last) # [B,C]\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc01a0b-612c-4ea5-975e-18f671d4a3f0",
   "metadata": {},
   "source": [
    "x: [B, T]\n",
    "\n",
    "emb: [B, T, D]\n",
    "\n",
    "packed: PackedSequence\n",
    "\n",
    "h_n: [L * dirs, B, H]\n",
    "\n",
    "last: [B, H]（单向）或 [B, 2H]（双向）\n",
    "\n",
    "logits: [B, C]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41806bbf-b12b-49ae-932c-faeeba20b7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_DIM = 100\n",
    "emb_layer, V = build_embedding_matrix(stoi, EMB_DIM, keyed_vectors=kv, freeze=True)\n",
    "model = RNNClassifier(emb=emb_layer, hidden=64, rnn_type=\"lstm\", bidirectional=False, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e51a9086-cc8e-499d-a191-7a455fe25de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349f77b5-3724-4134-940f-cd4cee11d96f",
   "metadata": {},
   "source": [
    "# 6. Train / validate with gradient clipping + early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9038422e-faf1-4155-b60f-331fadd78f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(dl, model, opt=None, clip_norm: float=1.0):\n",
    "    is_train = opt is not None\n",
    "    model.train(is_train)\n",
    "    total, correct, n = 0.0, 0, 0\n",
    "    for x, lengths, y in dl:\n",
    "        x, lengths, y = x.to(device), lengths.to(device), y.to(device)\n",
    "        logits = model(x, lengths)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        if is_train:\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=clip_norm)\n",
    "            opt.step()\n",
    "\n",
    "        total += float(loss) * y.size(0)\n",
    "        pred = logits.argmax(1)\n",
    "        correct += int((pred == y).sum())\n",
    "        n += y.size(0)\n",
    "    return total / n, correct / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8bbdf862-21b4-431e-89d3-cc4107e0d71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(model.parameters(), lr=3e-3)\n",
    "best_val, best_state, patience, bad = float(\"inf\"), None, 5, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ecda813a-8bcb-4ab6-8630-e91af5f576d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ep 01] train loss=0.683 acc=0.62 | valid loss=0.611 acc=1.00\n",
      "[ep 02] train loss=0.671 acc=0.62 | valid loss=0.592 acc=1.00\n",
      "[ep 03] train loss=0.665 acc=0.62 | valid loss=0.568 acc=1.00\n",
      "[ep 04] train loss=0.659 acc=0.62 | valid loss=0.544 acc=1.00\n",
      "[ep 05] train loss=0.657 acc=0.62 | valid loss=0.513 acc=1.00\n",
      "[ep 06] train loss=0.650 acc=0.62 | valid loss=0.483 acc=1.00\n",
      "[ep 07] train loss=0.644 acc=0.62 | valid loss=0.454 acc=1.00\n",
      "[ep 08] train loss=0.639 acc=0.62 | valid loss=0.428 acc=1.00\n",
      "[ep 09] train loss=0.629 acc=0.62 | valid loss=0.420 acc=1.00\n",
      "[ep 10] train loss=0.623 acc=0.62 | valid loss=0.413 acc=1.00\n",
      "[ep 11] train loss=0.616 acc=0.62 | valid loss=0.411 acc=1.00\n",
      "[ep 12] train loss=0.607 acc=0.62 | valid loss=0.408 acc=1.00\n",
      "[ep 13] train loss=0.596 acc=0.62 | valid loss=0.412 acc=1.00\n",
      "[ep 14] train loss=0.583 acc=0.62 | valid loss=0.417 acc=1.00\n",
      "[ep 15] train loss=0.569 acc=0.62 | valid loss=0.411 acc=1.00\n",
      "[ep 16] train loss=0.564 acc=0.62 | valid loss=0.427 acc=1.00\n",
      "[ep 17] train loss=0.538 acc=0.62 | valid loss=0.418 acc=1.00\n",
      "[EarlyStopping] no improve 5 epochs, stop.\n"
     ]
    }
   ],
   "source": [
    "for ep in range(1, 51):\n",
    "    tr_loss, tr_acc = run_epoch(train_dl, model, opt)\n",
    "    va_loss, va_acc = run_epoch(valid_dl, model, opt=None)\n",
    "    print(f\"[ep {ep:02d}] train loss={tr_loss:.3f} acc={tr_acc:.2f} | valid loss={va_loss:.3f} acc={va_acc:.2f}\")\n",
    "    if va_loss < best_val - 1e-4:\n",
    "        best_val, best_state, bad = va_loss, {k: v.cpu().clone() for k,v in model.state_dict().items()}, 0\n",
    "    else:\n",
    "        bad += 1\n",
    "        if bad >= patience:\n",
    "            print(f\"[EarlyStopping] no improve {patience} epochs, stop.\")\n",
    "            break\n",
    "\n",
    "\n",
    "if best_state:\n",
    "    model.load_state_dict(best_state)\n",
    "    model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b41e30f3-b0da-4f06-a962-734850a09d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Predict demo]\n",
      "  'this film is wonderful and touching' -> POSITIVE  probs=[0.171 0.829]\n",
      "  'awful boring movie with dull characters' -> POSITIVE  probs=[0.176 0.824]\n"
     ]
    }
   ],
   "source": [
    "# Quick inference\n",
    "label_names = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "def predict(texts: List[str]) -> List[Tuple[str, str, np.ndarray]]:\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        batch = [(encode(s), len(tok(s))) for s in texts]\n",
    "        ids, lens = zip(*batch)\n",
    "        lens = torch.tensor(lens, dtype=torch.long)\n",
    "        padded = pad_sequence(ids, batch_first=True, padding_value=pad_id)\n",
    "        # sort\n",
    "        lens, sort_idx = lens.sort(descending=True)\n",
    "        padded = padded.index_select(0, sort_idx).to(device)\n",
    "        logits = model(padded, lens.to(device))\n",
    "        probs = torch.softmax(logits, dim=1).cpu().numpy()\n",
    "        # restore order\n",
    "        inv = torch.argsort(sort_idx)\n",
    "        probs = probs[inv]\n",
    "        preds = probs.argmax(1)\n",
    "        return [(t, label_names[int(p)], pr) for t,p,pr in zip(texts, preds, probs)]\n",
    "\n",
    "print(\"\\n[Predict demo]\")\n",
    "for t, lab, pr in predict([\n",
    "    \"this film is wonderful and touching\",\n",
    "    \"awful boring movie with dull characters\"\n",
    "]):\n",
    "    print(f\"  {t!r} -> {lab}  probs={np.round(pr, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4446930f-138e-42a3-b375-5856a6f8b9bc",
   "metadata": {},
   "source": [
    "# 7. Word-level LM with LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2f0a4bf2-edef-4fcf-ae0c-2a23bb042f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_text = (\n",
    "    \"the movie is good but the pacing is slow . \"\n",
    "    \"the soundtrack is wonderful and the acting is great . \"\n",
    "    \"however the script is weak and the plot is boring . \"\n",
    ") * 20\n",
    "\n",
    "lm_vocab = sorted(set(tok(lm_text)))\n",
    "lm_stoi = {w:i for i, w in enumerate(lm_vocab)}\n",
    "lm_itos = {i:w for i, w in lm_stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0320aac9-6b93-4d97-ac57-c9aba1c4a5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_words(words):\n",
    "    return torch.tensor([lm_stoi[w] for w in words], dtype=torch.long)\n",
    "lm_ids = encode_words(tok(lm_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d8c7acf4-caa0-4d79-8e43-8d004558aa42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([14,  8,  7,  4,  3, 14,  9,  7, 12, 14, 13,  7, 16,  1, 14,  0,  7,  5,\n",
       "         6, 14, 11,  7, 15,  1, 14, 10,  7,  2, 14,  8,  7,  4,  3, 14,  9,  7,\n",
       "        12, 14, 13,  7, 16,  1, 14,  0,  7,  5,  6, 14, 11,  7, 15,  1, 14, 10,\n",
       "         7,  2, 14,  8,  7,  4,  3, 14,  9,  7, 12, 14, 13,  7, 16,  1, 14,  0,\n",
       "         7,  5,  6, 14, 11,  7, 15,  1, 14, 10,  7,  2, 14,  8,  7,  4,  3, 14,\n",
       "         9,  7, 12, 14, 13,  7, 16,  1, 14,  0,  7,  5,  6, 14, 11,  7, 15,  1,\n",
       "        14, 10,  7,  2, 14,  8,  7,  4,  3, 14,  9,  7, 12, 14, 13,  7, 16,  1,\n",
       "        14,  0,  7,  5,  6, 14, 11,  7, 15,  1, 14, 10,  7,  2, 14,  8,  7,  4,\n",
       "         3, 14,  9,  7, 12, 14, 13,  7, 16,  1, 14,  0,  7,  5,  6, 14, 11,  7,\n",
       "        15,  1, 14, 10,  7,  2, 14,  8,  7,  4,  3, 14,  9,  7, 12, 14, 13,  7,\n",
       "        16,  1, 14,  0,  7,  5,  6, 14, 11,  7, 15,  1, 14, 10,  7,  2, 14,  8,\n",
       "         7,  4,  3, 14,  9,  7, 12, 14, 13,  7, 16,  1, 14,  0,  7,  5,  6, 14,\n",
       "        11,  7, 15,  1, 14, 10,  7,  2, 14,  8,  7,  4,  3, 14,  9,  7, 12, 14,\n",
       "        13,  7, 16,  1, 14,  0,  7,  5,  6, 14, 11,  7, 15,  1, 14, 10,  7,  2,\n",
       "        14,  8,  7,  4,  3, 14,  9,  7, 12, 14, 13,  7, 16,  1, 14,  0,  7,  5,\n",
       "         6, 14, 11,  7, 15,  1, 14, 10,  7,  2, 14,  8,  7,  4,  3, 14,  9,  7,\n",
       "        12, 14, 13,  7, 16,  1, 14,  0,  7,  5,  6, 14, 11,  7, 15,  1, 14, 10,\n",
       "         7,  2, 14,  8,  7,  4,  3, 14,  9,  7, 12, 14, 13,  7, 16,  1, 14,  0,\n",
       "         7,  5,  6, 14, 11,  7, 15,  1, 14, 10,  7,  2, 14,  8,  7,  4,  3, 14,\n",
       "         9,  7, 12, 14, 13,  7, 16,  1, 14,  0,  7,  5,  6, 14, 11,  7, 15,  1,\n",
       "        14, 10,  7,  2, 14,  8,  7,  4,  3, 14,  9,  7, 12, 14, 13,  7, 16,  1,\n",
       "        14,  0,  7,  5,  6, 14, 11,  7, 15,  1, 14, 10,  7,  2, 14,  8,  7,  4,\n",
       "         3, 14,  9,  7, 12, 14, 13,  7, 16,  1, 14,  0,  7,  5,  6, 14, 11,  7,\n",
       "        15,  1, 14, 10,  7,  2, 14,  8,  7,  4,  3, 14,  9,  7, 12, 14, 13,  7,\n",
       "        16,  1, 14,  0,  7,  5,  6, 14, 11,  7, 15,  1, 14, 10,  7,  2, 14,  8,\n",
       "         7,  4,  3, 14,  9,  7, 12, 14, 13,  7, 16,  1, 14,  0,  7,  5,  6, 14,\n",
       "        11,  7, 15,  1, 14, 10,  7,  2, 14,  8,  7,  4,  3, 14,  9,  7, 12, 14,\n",
       "        13,  7, 16,  1, 14,  0,  7,  5,  6, 14, 11,  7, 15,  1, 14, 10,  7,  2,\n",
       "        14,  8,  7,  4,  3, 14,  9,  7, 12, 14, 13,  7, 16,  1, 14,  0,  7,  5,\n",
       "         6, 14, 11,  7, 15,  1, 14, 10,  7,  2, 14,  8,  7,  4,  3, 14,  9,  7,\n",
       "        12, 14, 13,  7, 16,  1, 14,  0,  7,  5,  6, 14, 11,  7, 15,  1, 14, 10,\n",
       "         7,  2])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1f65bb8d-cc7a-4b38-8524-f55b73b6da4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "LM_B, LM_T = 16, 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "138e9f7e-af69-4dc8-bcb8-f06becdc9dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lm_batch():\n",
    "    starts = torch.randint(0, len(lm_ids) - LM_T - 1, (LM_B,))\n",
    "    X = torch.stack([lm_ids[i:i+LM_T] for i in starts])\n",
    "    Y = torch.stack([lm_ids[i + 1 : i +LM_T+1] for i in starts])\n",
    "    return X.to(device), Y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ce939068-606c-4eb9-937a-25a810af1f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordLMLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, d_emb=64, hidden=128, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, d_emb)\n",
    "        self.rnn = nn.LSTM(d_emb, hidden, num_layers=num_layers, batch_first=True)\n",
    "        self.proj = nn.Linear(hidden, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        e = self.emb(x) # [B, T, d]\n",
    "        out, _ = self.rnn(e) # [B, T, H]\n",
    "        logits = self.proj(out) # [B, T, V]\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "96961a1a-2e8d-49a0-b4e9-44149db9c252",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_model = WordLMLSTM(vocab_size=len(lm_vocab)).to(device)\n",
    "lm_opt = torch.optim.Adam(lm_model.parameters(), lr=3e-3)\n",
    "lm_loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "536370b1-fce0-4426-93ed-95b9bef775dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lm_train(steps=300):\n",
    "    lm_model.train()\n",
    "    for step in range(1, steps + 1):\n",
    "        x, y = lm_batch()\n",
    "        logits = lm_model(x)\n",
    "        loss = lm_loss_fn(logits.reshape(-1, logits.size(-1)), y.reshape(-1))\n",
    "        lm_opt.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(lm_model.parameters(), 1.0)\n",
    "        lm_opt.step()\n",
    "        if step & 30 == 0:\n",
    "            ppl = math.exp(float(loss.detach().cpu()))\n",
    "            print(f\"[LM] step {step} loss={loss.item():.3f} ppl={ppl:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2d6a6980-cf17-477c-976c-f45a6af5fd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_itos_list = [None] * len(lm_stoi)\n",
    "for w, i in lm_stoi.items():\n",
    "    lm_itos_list[i] = w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a13221c0-f8fb-423e-8de7-b3ed2d1787fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lm_generate(prompt: List[str], max_new_tokens=20, temperature=1.0, top_k: Optional[int]=None):\n",
    "    lm_model.eval()\n",
    "    V = len(lm_itos_list)\n",
    "    with torch.no_grad():\n",
    "        ctx = [lm_stoi.get(w, 0) for w in prompt][-LM_T:] #use 1 TO LM_T words as the promt\n",
    "        for _ in range(max_new_tokens):\n",
    "            x = torch.tensor([ctx[-LM_T:]], dtype=torch.long, device=device)  # [1, T]\n",
    "            logits = lm_model(x)[:, -1, :] / max(temperature, 1e-8)\n",
    "            if top_k is not None:\n",
    "                v, i = torch.topk(logits, k=min(top_k, V), dim=-1) #clamp k to V\n",
    "                probs = F.softmax(v, dim=-1)\n",
    "                nxt = i[0, torch.multinomial(probs[0], 1).item()].item()\n",
    "            else:\n",
    "                probs = F.softmax(logits, dim=-1)\n",
    "                nxt = torch.multinomial(probs[0], 1).item()\n",
    "\n",
    "            if not (0 <= nxt < V):\n",
    "                nxt = 0\n",
    "            ctx.append(int(nxt))\n",
    "        return \" \".join(lm_itos_list[i] if 0 <= i < V else \"<unk>\" for i in ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3474ade0-a71b-4bc9-9b46-3072830c3a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LM] training tiny word-level LSTM for a few steps…\n",
      "[LM] step 1 loss=0.061 ppl=1.06\n",
      "[LM] step 32 loss=0.069 ppl=1.07\n",
      "[LM] step 33 loss=0.041 ppl=1.04\n",
      "[LM] step 64 loss=0.097 ppl=1.10\n",
      "[LM] step 65 loss=0.037 ppl=1.04\n",
      "[LM] step 96 loss=0.055 ppl=1.06\n",
      "[LM] step 97 loss=0.061 ppl=1.06\n",
      "[LM] step 128 loss=0.068 ppl=1.07\n",
      "[LM] step 129 loss=0.052 ppl=1.05\n",
      "[LM] step 160 loss=0.075 ppl=1.08\n",
      "[LM] step 161 loss=0.036 ppl=1.04\n",
      "[LM] step 192 loss=0.068 ppl=1.07\n",
      "[LM] step 193 loss=0.048 ppl=1.05\n",
      "[LM] step 224 loss=0.071 ppl=1.07\n",
      "[LM] step 225 loss=0.077 ppl=1.08\n",
      "[LM] step 256 loss=0.075 ppl=1.08\n",
      "[LM] step 257 loss=0.064 ppl=1.07\n",
      "[LM] step 288 loss=0.051 ppl=1.05\n",
      "[LM] step 289 loss=0.104 ppl=1.11\n",
      "[LM] sample: the pacing is slow the soundtrack is wonderful and the acting is great however the script is weak and the plot\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[LM] training tiny word-level LSTM for a few steps…\")\n",
    "lm_train(steps=300)\n",
    "print(\"[LM] sample:\", lm_generate([\"the\"], max_new_tokens=20, temperature=0.8, top_k=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a2ef25-588b-41c3-b0d8-dfbc2296cb85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
