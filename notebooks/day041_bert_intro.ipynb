{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf14d41b-5a9a-4018-9174-99e6783cc735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x108799050>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math, torch\n",
    "from transformers import AutoTokenizer, BertModel, BertForSequenceClassification, BertConfig\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47274888-40e7-45c6-b765-73d43ef38c57",
   "metadata": {},
   "source": [
    "# 0. load tokenizer and model (fast tokenizer, base model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51b3013d-a66e-4426-815c-bb54cf3b0649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c3afd5c656e4c65a566655e9eb911b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = \"bert-base-uncased\"\n",
    "tok = AutoTokenizer.from_pretrained(name, use_fast=True)\n",
    "model = BertModel.from_pretrained(name) #encoder only stack\n",
    "model.eval() #turn off dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63358010-a10e-4fe5-b7a3-f459cc3e2e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] vocab_size: 30522\n",
      "[Info] Hidden size / layers / heads: 768 12 12\n"
     ]
    }
   ],
   "source": [
    "print(\"[Info] vocab_size:\", tok.vocab_size)\n",
    "print(\"[Info] Hidden size / layers / heads:\",model.config.hidden_size, model.config.num_hidden_layers, model.config.num_attention_heads)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee156bf9-e510-4da9-9081-017e245a75eb",
   "metadata": {},
   "source": [
    "# 1. input representation: [CLS] / [SEP] + token_type_ids + attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21c96955-d560-48ef-a0ed-2f0166e4cf00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1] keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n",
      "[1] shapes: input_ids (1, 16) token_type_ids (1, 16) attention_mask (1, 16)\n",
      "[1] tokens: ['[CLS]', 'a', 'cat', 'sits', 'on', 'the', 'mat', '.', '[SEP]', 'an', 'animal', 'is', 'resting', 'indoors', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "premise = \"A cat sits on the mat.\"\n",
    "hypo = \"An animal is resting indoors.\"\n",
    "\n",
    "batch = tok(\n",
    "    premise,\n",
    "    hypo,\n",
    "    padding=\"max_length\",\n",
    "    max_length=16,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    "    return_token_type_ids=True\n",
    ")\n",
    "\n",
    "print(\"\\n[1] keys:\", batch.keys())\n",
    "print(\"[1] shapes:\",\n",
    "      \"input_ids\", tuple(batch[\"input_ids\"].shape),\n",
    "      \"token_type_ids\", tuple(batch[\"token_type_ids\"].shape),\n",
    "      \"attention_mask\", tuple(batch[\"attention_mask\"].shape))\n",
    "print(\"[1] tokens:\", tok.convert_ids_to_tokens(batch[\"input_ids\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "894ba1c4-c219-4a29-b5eb-c6090c87ff6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  1037,  4937,  7719,  2006,  1996, 13523,  1012,   102,  2019,\n",
       "          4111,  2003,  8345, 24274,  1012,   102]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "766f2eb4-9f09-4bff-b9f3-830c73dbd11b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"token_type_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "627bd457-bdd8-4815-bdbb-d1b853cbbbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence A token type id=0, B->1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c69943-71c6-4af7-adb3-20cca4536890",
   "metadata": {},
   "source": [
    "# 2. Encoder-only stack: no decoder / no causal mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05e7d42b-a0ad-4fbd-9377-b68f915b13dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward and shape: last_hidden_state [B, L, H], pooler_output [B, H], attention [B, heads, L, L]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12bbe72c-a60d-424c-afeb-a8a0d9e3f863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2] last_hidden_state: (1, 16, 768)\n",
      "[2] pooler_output: (1, 768)\n",
      "[2] num layers of attentions: 12 each (1, 12, 16, 16)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    out = model(**batch, output_attentions=True)\n",
    "print(\"\\n[2] last_hidden_state:\", tuple(out.last_hidden_state.shape))\n",
    "print(\"[2] pooler_output:\", tuple(out.pooler_output.shape))\n",
    "print(\"[2] num layers of attentions:\", len(out.attentions), \"each\", tuple(out.attentions[0].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19660a1a-03ac-4fa1-b8c8-e81a36a4e666",
   "metadata": {},
   "source": [
    "# 3. Input embeddings = Token + Position + Segment (then LN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1992a251-2c6d-4d50-9d44-bae23d3ec96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = batch[\"input_ids\"] #[1, L]\n",
    "segs = batch[\"token_type_ids\"] #[1, L]\n",
    "L = ids.size(1)\n",
    "pos = torch.arange(L).unsqueeze(0) #[1, L]\n",
    "\n",
    "with torch.no_grad():\n",
    "    we = model.embeddings.word_embeddings(ids)        #[1, L, H]\n",
    "    pe = model.embeddings.position_embeddings(pos)    #[1, L, H]\n",
    "    se = model.embeddings.token_type_embeddings(segs) #[1, L, H]\n",
    "    summed = we + pe + se\n",
    "    summed_ln = model.embeddings.LayerNorm(summed)    #ERT: sum → LayerNorm → Dropout\n",
    "    #official embeddings result (eval mode, off dropout)\n",
    "    official = model.embeddings(input_ids=ids, token_type_ids=segs, position_ids=pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf67a7bb-ca36-42e8-a8de-8801e7118e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(model.embeddings.LayerNorm, torch.nn.LayerNorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "de861b8f-c95e-4667-8daa-fa40e09b26fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[3] max |(token+pos+seg)->LN - embeddings.forward| =  4.768372e-07\n"
     ]
    }
   ],
   "source": [
    "diff = (summed_ln - official).abs().max().item()\n",
    "print(\"\\n[3] max |(token+pos+seg)->LN - embeddings.forward| = \", f\"{diff:.6e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77aca502-718b-47f7-baae-feaeb4ceb184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 验证：手动相加后过 LayerNorm，与 BERT 的 embeddings.forward 一致"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c9111a-60d1-4414-a689-d63ef510bfb4",
   "metadata": {},
   "source": [
    "# 4. Bidirectional demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ed732b7-bdf4-4c4a-b861-806139698abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[4] sentence tokens: ['[CLS]', 'i', 'went', 'to', 'the', 'bank', 'to', 'deposit', 'money', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "sent = \"I went to the bank to deposit money.\"\n",
    "pack = tok(\n",
    "    sent,\n",
    "    padding=False,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "tokens = tok.convert_ids_to_tokens(pack[\"input_ids\"][0])\n",
    "print(\"\\n[4] sentence tokens:\", tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f4db853-a3dc-4e7d-894d-4fc265533d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] 'bank' index: 5 token: bank\n"
     ]
    }
   ],
   "source": [
    "# find the position of \"bank\" (uncased WordPiece is \"bank\")\n",
    "try:\n",
    "    idx_bank = tokens.index(\"bank\")\n",
    "except ValueError:\n",
    "    #if cut into wordpieces, fallback mid position\n",
    "    idx_bank = len(tokens)//2\n",
    "\n",
    "print(\"[4] 'bank' index:\", idx_bank, \"token:\", tokens[idx_bank])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06492fef-4640-4fd3-875c-30242810cfa6",
   "metadata": {},
   "source": [
    "## 4.a default bidirectional padding-only mask all 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf5a4341-ae01-490d-a8af-6b00f7d660fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    out_bi = model(**pack).last_hidden_state #[1, L, H]\n",
    "    h_bi = out_bi[0, idx_bank]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9eda0b2-727e-41a9-9497-4d8e02e8914b",
   "metadata": {},
   "source": [
    "## 4.b 3D attention mask (lowertriangle=1, upper triangle=0) to only look left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b32512dc-01e2-48c0-990f-f1848911df21",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = pack[\"input_ids\"].size(1)\n",
    "tri = torch.tril(torch.ones(L, L, dtype=torch.long)).unsqueeze(0) #[1, L, L]\n",
    "with torch.no_grad():\n",
    "    out_uni = model(input_ids=pack[\"input_ids\"],\n",
    "                    attention_mask=tri,\n",
    "                    token_type_ids=None).last_hidden_state\n",
    "    h_uni = out_uni[0, idx_bank]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7c8e70-ed62-4eef-a8aa-f0a171faf2a5",
   "metadata": {},
   "source": [
    "## 4.c check the cosine similarity, if <1, then change by using the right information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "90981f03-f9aa-4376-b2d5-1314d30b94e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.c] cosine( bidirectional vs left-only ) at 'bank' = 0.3379  (the smaller the cos, the bigger the difference)\n"
     ]
    }
   ],
   "source": [
    "cos = torch.nn.functional.cosine_similarity(h_bi.unsqueeze(0), h_uni.unsqueeze(0)).item()\n",
    "print(f\"[4.c] cosine( bidirectional vs left-only ) at 'bank' = {cos:.4f}  (the smaller the cos, the bigger the difference)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fe10a2-f49f-4ab9-a621-4580c4494423",
   "metadata": {},
   "source": [
    "# 5. [CLS] as classification head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "19a75a7e-d1ea-447a-a4be-bb121c3fd98d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[5] classification logits shape: (1, 3)\n",
      "[5] argmax class: [0]\n"
     ]
    }
   ],
   "source": [
    "cfg = BertConfig.from_pretrained(name, num_labels=3) #suppose 3 classes\n",
    "clf = BertForSequenceClassification.from_pretrained(name, config=cfg)\n",
    "clf.eval()\n",
    "with torch.no_grad():\n",
    "    logits = clf(**batch).logits #[B, num_labels]\n",
    "print(\"\\n[5] classification logits shape:\", tuple(logits.shape))\n",
    "print(\"[5] argmax class:\", logits.argmax(-1).tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3df020e-d481-4a82-8b85-0d01baecfa74",
   "metadata": {},
   "source": [
    "# 6. Bonus: Base vs \"minimal\" config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "04dc911b-6d5f-4cf8-9a7a-d283ae0ae12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[6] mini BERT encoder layers: 2\n",
      "[6] This confirms: BERT is encoder-only (no decoder, no cross-attn).\n"
     ]
    }
   ],
   "source": [
    "mini_cfg = BertConfig(\n",
    "    covab_size=tok.vocab_size,\n",
    "    hidden_size=128,\n",
    "    num_hidden_layers=2,\n",
    "    num_attention_heads=4,\n",
    "    intermediate_size=256,\n",
    "    pad_token_id=tok.pad_token_id\n",
    ")\n",
    "\n",
    "mini = BertModel(mini_cfg) #random initialized mini berg (encoder only)\n",
    "with torch.no_grad():\n",
    "    _ = mini(**batch)\n",
    "\n",
    "print(\"\\n[6] mini BERT encoder layers:\", len(mini.encoder.layer))\n",
    "print(\"[6] This confirms: BERT is encoder-only (no decoder, no cross-attn).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49baf9a9-b44f-4260-bc83-d2f9702bf58a",
   "metadata": {},
   "source": [
    "* 三件套嵌入真实相加（token + position + segment → LayerNorm）与 BERT 内部实现一致。\n",
    "\n",
    "* 默认注意力是双向的（没有因果上三角遮罩）；我们强行加了“只看左边”的 3D mask，结果该词位的表示明显改变 ⇒ 证明默认是利用右侧上下文的。\n",
    "\n",
    "* BERT 是纯 Encoder 堆叠；BertForSequenceClassification 直接在 [CLS] 上加线性头即可下游分类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff00d9a-9ea0-413b-ad4b-c30996e741d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
