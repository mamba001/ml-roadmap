{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39708c9b-b93a-4cdf-af95-1637bf378519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(42)\n",
    "DEVICE = \"mps\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b761a5-432d-446a-ae6f-77b2180da6d8",
   "metadata": {},
   "source": [
    "# 1. Multi_head attention (MHA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b2feba8-01b7-48c0-a686-524316c23587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] shapes: Q torch.Size([2, 4, 8]) scores torch.Size([2, 2, 4, 4]) head_out torch.Size([2, 2, 4, 4]) out torch.Size([2, 4, 8])\n",
      "[1] param count ~ 256 (≈ 4*d_model^2)\n"
     ]
    }
   ],
   "source": [
    "B, T, d_model, h = 2, 4, 8, 2\n",
    "d_k = d_model // h\n",
    "\n",
    "x = torch.randn(B, T, d_model)\n",
    "\n",
    "Wq = torch.randn(d_model, d_model)\n",
    "Wk = torch.randn(d_model, d_model)\n",
    "Wv = torch.randn(d_model, d_model)\n",
    "Wo = torch.randn(d_model, d_model)\n",
    "\n",
    "Q = x @ Wq\n",
    "K = x @ Wk\n",
    "V = x @ Wv\n",
    "\n",
    "def split_heads(t):\n",
    "    return t.view(B, T, h, d_k).transpose(1, 2) #[B, h, T, d_k]\n",
    "\n",
    "Qh, Kh, Vh = map(split_heads, (Q, K, V))\n",
    "\n",
    "#attention per head scores [B, h, T, T]\n",
    "scores = torch.matmul(Qh, Kh.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "attn = scores.softmax(dim=-1)\n",
    "\n",
    "# within head [B, h, T, d_k]\n",
    "head_out = torch.matmul(attn, Vh)\n",
    "\n",
    "# back to []B, T, d], then multiply Wo\n",
    "out = head_out.transpose(1, 2).contiguous().view(B, T, d_model) @ Wo\n",
    "\n",
    "print(\"[1] shapes:\",\n",
    "      \"Q\", Q.shape, \"scores\", scores.shape, \"head_out\", head_out.shape, \"out\", out.shape)\n",
    "print(\"[1] param count ~\", Wq.numel()+Wk.numel()+Wv.numel()+Wo.numel(), \"(≈ 4*d_model^2)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67891e2-3a44-4acf-8921-9c88ce0e491a",
   "metadata": {},
   "source": [
    "# 2. Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6448fcf-389b-4e8a-9b24-1727590f5612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2] weights with pad mask: torch.Size([1, 2, 4, 4])\n",
      "    col sums of masked keys ~ 0?: 0.0\n"
     ]
    }
   ],
   "source": [
    "attn_mod = nn.MultiheadAttention(embed_dim=8, num_heads=2, batch_first=True)\n",
    "\n",
    "x = torch.randn(1, 4, 8) #[1,4,8]\n",
    "\n",
    "#suppose last two positions are PAD\n",
    "key_padding_mask = torch.tensor([[False, False, True, True]]) # [B,T]\n",
    "\n",
    "y, w = attn_mod(x, x, x, key_padding_mask = key_padding_mask, need_weights=True, average_attn_weights=False)\n",
    "print(\"[2] weights with pad mask:\", w.shape)  # [B,h,T_q,T_k]\n",
    "print(\"    col sums of masked keys ~ 0?:\", w[0,0,:,2:].sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3361ee79-40ab-4a02-9f16-06579ce77fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2] causal upper triangle masked? head0 row0-> future cols sum ~ 0: 0.0\n"
     ]
    }
   ],
   "source": [
    "T = x.size(1)\n",
    "causal = torch.triu(torch.ones(T, T, dtype=torch.bool), diagonal=1) #[T,T]\n",
    "y2, w2 = attn_mod(x, x, x, key_padding_mask=key_padding_mask, attn_mask=causal, need_weights=True, average_attn_weights=False)\n",
    "print(\"[2] causal upper triangle masked? head0 row0-> future cols sum ~ 0:\", w2[0,0,0,1:].sum().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08111272-5a65-4c2e-8d0b-746252efbf35",
   "metadata": {},
   "source": [
    "# 3. Pre-LN vs Post-LN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24bee38e-e558-452e-9116-44aa0160303e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreLNBlock(nn.Module):\n",
    "    def __init__(self, d=16, h=2):\n",
    "        super().__init__()\n",
    "        self.ln1 = nn.LayerNorm(d)\n",
    "        self.attn = nn.MultiheadAttention(d, h, batch_first=True)\n",
    "        self.ln2 = nn.LayerNorm(d)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d, 4*d),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(4*d, d),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.ln1(x)\n",
    "        a, _ = self.attn(h, h, h, need_weights=False)\n",
    "        x = x + a\n",
    "        h = self.ln2(x)\n",
    "        f = self.ffn(h)\n",
    "        x = x + f\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d92e842-1b02-4850-94f2-c3c1bdd1930c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PostLNBlock(nn.Module):\n",
    "    def __init__(self, d=16, h=2):\n",
    "        super().__init__()\n",
    "        self.attn = nn.MultiheadAttention(d, h, batch_first=True)\n",
    "        self.ln1 = nn.LayerNorm(d) \n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d, 4*d),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(4*d, d),\n",
    "        )\n",
    "        self.ln2 = nn.LayerNorm(d)\n",
    "\n",
    "    def forward(self, x):\n",
    "        a, _ = self.attn(x, x, x, need_weights=False)\n",
    "        x = self.ln1(a + x)\n",
    "        f = self.ffn(x)\n",
    "        x = self.ln2(f + x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d301e61a-d533-4b2d-ae27-7466394a85b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] Pre-LN out shape: torch.Size([2, 5, 16])\n",
      "[3] Post-LN out shape: torch.Size([2, 5, 16])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 5, 16)\n",
    "print(\"[3] Pre-LN out shape:\", PreLNBlock()(x).shape)\n",
    "print(\"[3] Post-LN out shape:\", PostLNBlock()(x).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad69e5c7-6bdd-465b-b6a4-bfe29cda5bca",
   "metadata": {},
   "source": [
    "# 4. Positional encoding: sinusoidal/learned/relative/R(rotation)oPE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f58b56-741d-40ce-86b1-b75764367b9c",
   "metadata": {},
   "source": [
    "## 4.1 Sinusoidal (fixed) + learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5217f31-6554-41b6-b284-26188ac03da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "B, T, d = 1, 6, 8\n",
    "tok = torch.randn(B, T, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1062f82a-7fd2-4bff-a8f9-1356a432420a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4A] sinusoidal added shape: torch.Size([1, 6, 8])\n"
     ]
    }
   ],
   "source": [
    "# Sinusoidal\n",
    "pos = torch.arange(T).unsqueeze(1) #[T,1]\n",
    "div = torch.exp(torch.arange(0, d, 2) * (-math.log(10000.0)/d)) #[d/2]\n",
    "pe = torch.zeros(T, d) #[T, d]\n",
    "pe[:, 0::2] = torch.sin(pos * div)\n",
    "pe[:, 1::2] = torch.cos(pos * div)\n",
    "tok_sin = tok + pe.unsqueeze(0)\n",
    "print(\"[4A] sinusoidal added shape:\", tok_sin.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5de495b2-3caa-47fb-9db1-93c2e68ae8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4A] learned added shape: torch.Size([1, 6, 8])\n"
     ]
    }
   ],
   "source": [
    "# learned\n",
    "pos_emb = nn.Embedding(512, d) #learned table\n",
    "pos_ids = torch.arange(T).unsqueeze(0) #[1, T]\n",
    "tok_learned = tok + pos_emb(pos_ids)\n",
    "print(\"[4A] learned added shape:\", tok_learned.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9158561-25c0-43fd-99a7-874144cca705",
   "metadata": {},
   "source": [
    "## 4.2 Relative position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "48413e66-4411-4539-9d85-bc2e144bb3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_position_bucket(rel_pos, num_buckets=8, max_distance=32):\n",
    "    # simplified: small distance -> linear buckets, large distance -> log buckets\n",
    "    ret = torch.zeros_like(rel_pos)\n",
    "    n = rel_pos.abs()\n",
    "    max_exact = num_buckets // 2\n",
    "    is_small = n < max_exact\n",
    "    ret[is_small] = n[is_small]\n",
    "    # large distance\n",
    "    n_large = n.clone().clamp_min(max_exact)\n",
    "    val = max_exact + (\n",
    "        (torch.log(n_large.float()/max_exact) / math.log(max_distance/max_exact)) * (num_buckets - max_exact)\n",
    "    ).long().clamp_max(num_buckets - 1 - max_exact)\n",
    "    ret[~is_small] = val[~is_small]\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b90b0aa9-31a9-4955-9181-abb23214d17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explain what above code doing...\n",
    "# rel_pos is relative positions, such as i - j, shape normally [T_q, T_k]\n",
    "# output same shape as rel_pos, each element is the id of buckets, from 0 to num_buckets-1\n",
    "\n",
    "# then max_exact is dividing buckets into two sets, \n",
    "# first half [0, num_exact-1] for precise small distance and second half [num_exact, num_buckets-1] for large distance and log compression\n",
    "\n",
    "# small distance directly using distance as id of buckets from 1 to max_exact-1\n",
    "# for large distance, copy and clamp the min to max_exact\n",
    "# 详细分解：\n",
    "\n",
    "#n_large / max_exact → 把阈值点对齐到 1。\n",
    "\n",
    "#log(n_large/max_exact) / log(max_distance/max_exact) → 把对数值归一化到 [0,1]。\n",
    "\n",
    "#* (num_buckets - max_exact) → 线性放大到后半桶的区间长度。\n",
    "\n",
    "#+ max_exact → 平移，让索引落到后半区间（如 4~7）。\n",
    "\n",
    "#.long() → 取整（向下取整），得到离散桶号。\n",
    "\n",
    "#.clamp_max(num_buckets - 1 - max_exact) → 限制映射不超过后半区间最大偏移量（超出 max_distance 的距离都挤到最后一个桶）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0cc89d8b-335b-4c10-bd4f-609b7b354be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eg\n",
    "#设 num_buckets=8, max_distance=32：\n",
    "\n",
    "#距离 n=0,1,2,3 → 直接映射到桶 0,1,2,3（线性、精确）。\n",
    "\n",
    "#距离 n=4..32 → 映射到桶 4..7（对数压缩，越远越“挤”到高桶）。\n",
    "\n",
    "#距离 n>32 → 统一映射到最后一个桶 7（上限截断）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f4ad70cf-673f-4429-9387-5811a21d7d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4B] relative bias per-head shape: torch.Size([2, 6, 6])\n"
     ]
    }
   ],
   "source": [
    "Tq=Tk=T\n",
    "q_pos = torch.arange(Tq).unsqueeze(1)            # [T,1]\n",
    "k_pos = torch.arange(Tk).unsqueeze(0)            # [1,T]\n",
    "rel = q_pos - k_pos                              # [T,T]  (i-j)\n",
    "buckets = relative_position_bucket(rel)          # [T,T]\n",
    "rel_bias_table = nn.Embedding(8, 2)              # 假设2头 -> 每桶2维\n",
    "bias = rel_bias_table(buckets).permute(2,0,1)    # [2,T,T] -> per-head bias\n",
    "print(\"[4B] relative bias per-head shape:\", bias.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d65f772-b58c-4180-872d-127291cefd1a",
   "metadata": {},
   "source": [
    "## 4.3 RoPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4823b31e-6e59-4133-939c-bbb5cc2a0da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rope_apply(q, k):\n",
    "    \"\"\"\n",
    "    q, k: [B, h, T, d], assume d is even number, do rotation on every pair of dimension (2i, 2i+1)\n",
    "    \"\"\"\n",
    "    B, H, T, D = q.shape\n",
    "    half = D // 2\n",
    "    freqs = torch.exp(torch.arange(0, half) * (-math.log(10000.0)/half)) #[D/2]\n",
    "    pos = torch.arange(T)[:, None] #[T,1]\n",
    "    ang = pos * freqs[None, :] #[T, D/2]\n",
    "    sin, cos = ang.sin(), ang.cos()\n",
    "\n",
    "    def split2(x):\n",
    "        return x[..., : half], x[..., half:]\n",
    "\n",
    "    q1, q2 = split2(q)\n",
    "    k1, k2 = split2(k)\n",
    "\n",
    "    # rotation: (x1, x2) -> (x1 * cos - x2 * sin, x1 * sin + x2 * cos)\n",
    "    def rot(x1, x2):\n",
    "        # need broadcast [T, D/2] into [B, H, T, D/2]\n",
    "        return (x1 * cos[None, None, :, :] - x2 * sin[None, None, :, :],\n",
    "                x1 * sin[None, None, :, :] + x2 * cos[None, None, :, :])\n",
    "\n",
    "    rq1, rq2 = rot(q1, q2)\n",
    "    rk1, rk2 = rot(k1, k2)\n",
    "    rq = torch.cat([rq1, rq2], dim=-1)\n",
    "    rk = torch.cat([rk1, rk2], dim=-1)\n",
    "    return rq, rk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4fe3adcd-f1b9-4be2-be83-472bcdeded1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4C] rope/no_rope score shapes: torch.Size([1, 2, 5, 5]) torch.Size([1, 2, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "B,H,T,D = 1,2,5,8\n",
    "q = torch.randn(B,H,T,D); k = torch.randn(B,H,T,D)\n",
    "rq, rk = rope_apply(q,k)\n",
    "# 对比未加 vs 加RoPE后不同行的点积，体现“相对”位置信息\n",
    "no_rope_scores = (q @ k.transpose(-2,-1)) / math.sqrt(D)\n",
    "rope_scores   = (rq @ rk.transpose(-2,-1)) / math.sqrt(D)\n",
    "print(\"[4C] rope/no_rope score shapes:\", rope_scores.shape, no_rope_scores.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69200eac-813e-44ca-8f25-ddd648694fc6",
   "metadata": {},
   "source": [
    "# 5. Label smoothing, warmup LR, grad clipping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d82fe4-f21c-4737-b6fe-76bb1204f406",
   "metadata": {},
   "source": [
    "## 5.1 Label smoothing vs cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "84431bfc-29c5-4d50-ab60-31c95eb5ac28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5A] CE: 2.4806559085845947   CE with LS(0.1): 2.4492783546447754\n"
     ]
    }
   ],
   "source": [
    "B, V = 3, 5\n",
    "logits = torch.randn(B, V)\n",
    "targets = torch.tensor([1, 3, 0])\n",
    "\n",
    "# typical cross entropy\n",
    "ce = F.cross_entropy(logits, targets, reduction=\"mean\")\n",
    "\n",
    "# Label smoothing\n",
    "eps = 0.1\n",
    "logp = F.log_softmax(logits, dim=-1) #[B,V]\n",
    "nll = F.nll_loss(logp, targets, reduction=\"mean\")\n",
    "ls = -logp.mean()\n",
    "ce_ls = (1 - eps) * nll + eps * ls\n",
    "\n",
    "print(\"[5A] CE:\", ce.item(), \"  CE with LS(0.1):\", ce_ls.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbd45b2-ad49-40c1-ba6b-f99e01a2a20e",
   "metadata": {},
   "source": [
    "## 5.2 Warmup + Inverse Sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8f17ddd1-7494-4917-affb-48fec5f65691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5B] first 10 warmup+inv-sqrt lrs: ['0.000000', '0.000001', '0.000001', '0.000001', '0.000002', '0.000002', '0.000002', '0.000003', '0.000003', '0.000003']\n"
     ]
    }
   ],
   "source": [
    "def transformer_lr(step, d_model=128, warmup=4000):\n",
    "    step = max(1, step)\n",
    "    return (d_model ** -0.5) * min(step ** -0.5, step * (warmup ** -1.5))\n",
    "\n",
    "lrs = [transformer_lr(s) for s in range(1, 11)]\n",
    "print(\"[5B] first 10 warmup+inv-sqrt lrs:\", [f\"{x:.6f}\" for x in lrs])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85aa12d-97c7-4cf4-a4f5-1235311d6ab4",
   "metadata": {},
   "source": [
    "## 5.3 Gradient clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1f5c0968-24f9-4493-a4a1-9c52e681779a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5C] grad norm before ~1250.979, after ~1.000\n"
     ]
    }
   ],
   "source": [
    "lin = nn.Linear(64, 64)\n",
    "x = torch.randn(128, 64)\n",
    "y = lin(x).sum()\n",
    "y.backward()\n",
    "before = torch.nn.utils.clip_grad_norm_(lin.parameters(), max_norm=1.0) # total norm before clipping\n",
    "after = 0.0\n",
    "for p in lin.parameters():\n",
    "    if p.grad is not None:\n",
    "        after += p.grad.norm().item()**2\n",
    "after = after ** 0.5\n",
    "print(f\"[5C] grad norm before ~{before:.3f}, after ~{after:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9f0628-28ba-45e7-986a-c8c2693ed413",
   "metadata": {},
   "source": [
    "# 6. Decoder & KV Cache: step generation vs. full forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e74c5663-7720-41ec-85d1-94a16ffbea6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6] step-vs-full allclose? -> True\n"
     ]
    }
   ],
   "source": [
    "class MiniSelfAttn(nn.Module):\n",
    "    def __init__(self, d=16, h=2):\n",
    "        super().__init__()\n",
    "        self.d = d\n",
    "        self.h = h\n",
    "        self.dk = d // h\n",
    "        self.Wq = nn.Linear(d, d, bias=False)\n",
    "        self.Wk = nn.Linear(d, d, bias=False)\n",
    "        self.Wv = nn.Linear(d, d, bias=False)\n",
    "        self.out = nn.Linear(d, d, bias=False)\n",
    "\n",
    "    def split(self, x): # [B, T, d] -> [B, h, T, dk]\n",
    "        B, T, _ = x.shape\n",
    "        return x.view(B, T, self.h, self.dk).transpose(1, 2)\n",
    "\n",
    "    def merge(self, xh): #[B, h, T, dk] -> [B, T, d]\n",
    "        B, _, T, _ = xh.shape\n",
    "        return xh.transpose(1, 2).contiguous().view(B, T, self.d)\n",
    "\n",
    "    def full_forward(self, y): #full (with causal)\n",
    "        Q = self.split(self.Wq(y))\n",
    "        K = self.split(self.Wk(y))\n",
    "        V = self.split(self.Wv(y))\n",
    "        B, H, T, _ = Q.shape\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.dk)\n",
    "        causal = torch.triu(torch.ones(T, T), diagonal=1).bool()\n",
    "        scores = scores.masked_fill(causal, float(\"-inf\"))\n",
    "        attn = scores.softmax(-1)\n",
    "        out = self.merge(torch.matmul(attn, V))\n",
    "        return self.out(out)\n",
    "\n",
    "    def step(self, y_t, cache): # step wise + cache\n",
    "        # y_t: [B, 1, d]\n",
    "        q = self.split(self.Wq(y_t))\n",
    "        k = self.split(self.Wk(y_t))\n",
    "        v = self.split(self.Wv(y_t)) # all [B, h, 1, dk]\n",
    "\n",
    "        K = k if cache[\"K\"] is None else torch.cat([cache[\"K\"], k], dim=2) #[B, h, t, dk]\n",
    "        V = v if cache[\"V\"] is None else torch.cat([cache[\"V\"], v], dim=2)\n",
    "        cache[\"K\"] = K\n",
    "        cache[\"V\"] = V\n",
    "        scores = torch.matmul(q, K.transpose(-2, -1)) / math.sqrt(self.dk)\n",
    "        attn = scores.softmax(-1)\n",
    "        out = self.merge(torch.matmul(attn, V))\n",
    "        return self.out(out), cache\n",
    "\n",
    "\n",
    "\n",
    "B,T,d,h = 1, 5, 16, 2\n",
    "y = torch.randn(B,T,d)\n",
    "cell = MiniSelfAttn(d=d,h=h)\n",
    "\n",
    "# 全量最后一步输出\n",
    "full_last = cell.full_forward(y)[:, -1, :]  # [B,d]\n",
    "\n",
    "# 逐步生成（KV cache）\n",
    "cache = {\"K\": None, \"V\": None}\n",
    "out_t = None\n",
    "for t in range(T):\n",
    "    out_t, cache = cell.step(y[:, t:t+1, :], cache)  # [B,1,d]\n",
    "\n",
    "step_last = out_t[:, 0, :]                           # [B,d]\n",
    "print(\"[6] step-vs-full allclose? ->\", torch.allclose(full_last, step_last, atol=1e-5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfb49d9-609a-4d96-8415-1aa9d12e9e5d",
   "metadata": {},
   "source": [
    "# 7. Complexity intuition: O(T^2) and attention matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c7408563-d132-4a2e-92bd-a4d2b7ad443f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7] avg time @T=64: 0.21 ms (应随 T^2 增长)\n",
      "[7] avg time @T=128: 0.45 ms (应随 T^2 增长)\n",
      "[7] avg time @T=256: 0.87 ms (应随 T^2 增长)\n",
      "[7] avg time @T=512: 3.68 ms (应随 T^2 增长)\n",
      "[7] attn matrix T=256: ~0.25 MB per head/batch\n",
      "[7] attn matrix T=512: ~1.00 MB per head/batch\n",
      "[7] attn matrix T=1024: ~4.00 MB per head/batch\n"
     ]
    }
   ],
   "source": [
    "def naive_attn_time(B=2, h=4, T=256, d_k=64, iters=10):\n",
    "    Q = torch.randn(B, h, T, d_k)\n",
    "    K = torch.randn(B, h, T, d_k)\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    for _ in range(iters):\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) #[B, h, T, T], the key O(T^2)\n",
    "        _ = scores.softmax(-1)\n",
    "\n",
    "\n",
    "    return (time.perf_counter() - t0) / iters\n",
    "\n",
    "for T in [64, 128, 256, 512]:\n",
    "    dt = naive_attn_time(T=T)\n",
    "    print(f\"[7] avg time @T={T}: {dt*1000:.2f} ms (应随 T^2 增长)\")\n",
    "\n",
    "# 注意力矩阵内存估算（float32：4字节）\n",
    "for T in [256, 512, 1024]:\n",
    "    bytes_mat = (T*T*4)\n",
    "    print(f\"[7] attn matrix T={T}: ~{bytes_mat/1024/1024:.2f} MB per head/batch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b755f669-863f-4951-9ff2-fc2a1f6d1e00",
   "metadata": {},
   "source": [
    "# 8. Diagnosis and visualization: weights row sum / masking / heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bad4715d-8671-49dc-a4e4-9e589c6c2933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attn row sum ~= 1, pad column ~= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1dfd2992-921d-441e-88e2-b3c147bca207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8] row sums (≈1): tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       grad_fn=<SumBackward1>)\n",
      "[8] masked cols sum (≈0): tensor(0., grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "attn_mod = nn.MultiheadAttention(embed_dim=16, num_heads=2, batch_first=True)\n",
    "x = torch.randn(1, 6, 16)\n",
    "pad = torch.tensor([[False, False, False, True, True, True]])  # last three positions PAD\n",
    "\n",
    "_, w = attn_mod(x, x, x, key_padding_mask=pad, need_weights=True, average_attn_weights=False)  # [B,h,T,T]\n",
    "w = w[0,0]  #  head0: [T,T]\n",
    "\n",
    "print(\"[8] row sums (≈1):\", w.sum(-1))\n",
    "print(\"[8] masked cols sum (≈0):\", w[:, 3:].sum())\n",
    "\n",
    "plt.imshow(w.detach().numpy(), aspect='auto')     # visualize the attention weights\n",
    "plt.colorbar(); plt.title(\"Head0 Attention (with pad mask)\")\n",
    "plt.xlabel(\"Keys (columns)\"); plt.ylabel(\"Queries (rows)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04d6443-f221-4a87-a4f8-8e9c7daf78f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
