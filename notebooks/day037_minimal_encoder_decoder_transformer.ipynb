{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35465b08-be5f-4ffd-acb6-33452d3ccc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Optional, List\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d3dcadc-3e35-4f8d-8641-5248d58f7813",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "DEVICE = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d20fa31b-87cf-4191-82f9-f30315bb6589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e97d0e9-6ec7-41cb-8231-a75ccb9fbdda",
   "metadata": {},
   "source": [
    "# 1. Intuition to attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fdb37c-765c-4896-a63d-0512d0ec3adf",
   "metadata": {},
   "source": [
    "## 1.1 What is attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b1ac52-c0c0-42ab-b5e7-4f445eccfb8f",
   "metadata": {},
   "source": [
    "我有三份信息（Values, V）要综合，比如 V1, V2, V3；我手上还有一组权重（weights），比如 0.7, 0.2, 0.1（加起来=1）。\n",
    "那综合结果就是：0.7*V1 + 0.2*V2 + 0.1*V3。\n",
    "——这就是注意力结果（只不过真正的权重不是手填，而是“算出来”的）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b04a291e-ce4a-4ab3-8adb-a1aaaf0f0c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.5 2.5]\n"
     ]
    }
   ],
   "source": [
    "def weighted_average(values, weights):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    values: np.ndarray, shape [N, D] N informations, each is D-dimentional vector\n",
    "    weights: np.ndarray, shape [N]\n",
    "\n",
    "    Outputs:\n",
    "    out: np.ndarray, shape[D],= weighted average\n",
    "    \"\"\"\n",
    "    weights = weights / (weights.sum() + 1e-12) #normalization\n",
    "    return (weights[:, None] * values).sum(axis=0)\n",
    "\n",
    "V = np.array([[10., 0.],   # V1\n",
    "              [ 0.,10.],   # V2\n",
    "              [ 5., 5.]])  # V3   \n",
    "w = np.array([0.7, 0.2, 0.1]) \n",
    "out = weighted_average(V, w)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20267e2b-0259-4edf-b46d-be99440a766b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.5, 2.5])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w @ V"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de895e1-ae32-4ef9-b2db-81414a924237",
   "metadata": {},
   "source": [
    "## 1.2 Where is weight from?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadd18ef-3ac5-47a4-8426-888846c902de",
   "metadata": {},
   "source": [
    "想法：\n",
    "\n",
    "* 我有一个“问题”向量 Q（Query），表示“我现在想要什么”。\n",
    "\n",
    "* 还有一堆“候选”向量 K（Keys），每个候选都有对应的 V（Values） 信息。\n",
    "\n",
    "* 打分：用 Q 去和每个 K 做“相似度”（我们用点积，越像分越高）。\n",
    "\n",
    "* 归一化：把这些分数做 softmax（指数归一化）→ 得到 0~1 的权重，且和=1。\n",
    "\n",
    "* 带权平均：用这些权重去加权 V，得到输出。\n",
    "\n",
    "这就是常说的 Scaled Dot-Product Attention（缩放点积注意力）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "160b0c0f-3686-484e-b42d-bcbcd1918612",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "    x: np.ndarray, shape[N]\n",
    "\n",
    "    output:\n",
    "    p: np.ndarray, shape[N]\n",
    "\n",
    "    how it works:\n",
    "    p[i] = exp(x[i]) / sum(exp(x[j]))\n",
    "    \"\"\"\n",
    "    x = x - x.max()\n",
    "    e = np.exp(x)\n",
    "    return e / (e.sum() + 1e-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82abbd63-c74f-4665-a8ab-ce7ccb8f6740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_once(Q, K, V):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "    Q: np.ndarary, shape[D] one query vector\n",
    "    K: np.ndarray, shape[N, D] N keys\n",
    "    V: np.ndarray, shape[N, Dv] every key corresponding values\n",
    "\n",
    "    output:\n",
    "    out: np.ndarray, shape [Dv] attention output\n",
    "    weights: np.ndarray, shape [N] attention weights (sum == 1)\n",
    "\n",
    "    how it works:\n",
    "    1) scores[i] = dot(Q, K[i])\n",
    "    2) weights = softmax(scores)\n",
    "    3) out = sum(weights[i] * V[i]) over i\n",
    "    \"\"\"\n",
    "\n",
    "    scores = K @ Q\n",
    "\n",
    "    weights = softmax(scores)\n",
    "\n",
    "    out = weighted_average(V, weights)\n",
    "\n",
    "    return out, weights, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddc13b7d-a396-4460-8d3f-b71234fb83c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "打分 scores : [ 1.   0.7 -1. ]\n",
      "权重 weights: [0.53300543 0.39486013 0.07213444]\n",
      "输出 out    : [5.69072648 4.30927352]\n"
     ]
    }
   ],
   "source": [
    "Q = np.array([1.0, 0.0])                    # I would like the information along x axis\n",
    "K = np.array([[1.0, 0.0],                   # K1, same as Q, along with it\n",
    "              [0.7, 0.2],                   # K2, sort of align with Q\n",
    "              [-1.0, 0.0]])                 # K3, opposite direction of W\n",
    "V = np.array([[10., 0.],                    # V1\n",
    "              [ 0.,10.],                    # V2\n",
    "              [ 5., 5.]], dtype=np.float32) # V3\n",
    "\n",
    "out, w, s = attention_once(Q, K, V)\n",
    "print(\"打分 scores :\", s)       # 看哪个最相关（越大越相关）\n",
    "print(\"权重 weights:\", w)       # softmax 后变为概率分布（和=1）\n",
    "print(\"输出 out    :\", out)     # 带权平均的结果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c4013e-eb76-4654-b0e0-de1e6f5256d2",
   "metadata": {},
   "source": [
    "need * 1/sqrt(D) if large"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643a0492-158f-442f-b541-a022f923aa3e",
   "metadata": {},
   "source": [
    "## 1.3 What is mask?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b00a7e1-346a-47c4-990a-0e6796d8b4e3",
   "metadata": {},
   "source": [
    "* Padding Mask（填充掩码）：补齐出来的 <pad> 位置是“无效的”，权重要变成 0。\n",
    "做法：在分数上把这些位置加上一个超大负数（如 -1e9），softmax 后几乎就是 0。\n",
    "\n",
    "* Causal Mask（因果掩码）：解码时不能看未来（当前位置只能看它前面），把“未来位置”也加上超大负数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bec80276-b589-4151-a097-76f48c1bb5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_mask(scores, mask):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    scores: np.ndarray, shape [N], original score\n",
    "    mask: np.ndarray, shape [N], dtype = bool, True means need to mask that position\n",
    "\n",
    "    output:\n",
    "    masked_score: np.ndarray, shape [N]\n",
    "\n",
    "    how it works:\n",
    "    make mask==True position extremely small, after softmax, it will very close to 0\n",
    "    \"\"\"\n",
    "\n",
    "    masked = scores.copy()\n",
    "    masked[mask] = -1e9\n",
    "    return masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81fc3093-5b65-498d-ab0f-74e8cc27c462",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.array([3.0, 1.0, -2.0], dtype=np.float32)\n",
    "mask   = np.array([False, True, False])  # 第二个位置是 pad，要遮住\n",
    "masked_scores = apply_mask(scores, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69b414a6-52ab-4b9f-a87e-e2bd41f94149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原分数: [ 3.  1. -2.] -> softmax [0.8756006  0.11849965 0.00589975]\n",
      "打掩码: [ 3.e+00 -1.e+09 -2.e+00] -> softmax [0.9933072  0.         0.00669285]\n"
     ]
    }
   ],
   "source": [
    "print(\"原分数:\", scores, \"-> softmax\", softmax(scores))\n",
    "print(\"打掩码:\", masked_scores, \"-> softmax\", softmax(masked_scores))  # 中间那个几乎 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8aae04-8c63-4e4e-94fe-cfe9021a29ad",
   "metadata": {},
   "source": [
    "## 1.4 Self-attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5bed55-a648-4aeb-80ec-9c108dfe19a6",
   "metadata": {},
   "source": [
    "关键：现在 Q/K/V 都来自同一句话的向量表示 X。\n",
    "最简单的演示：我们先不做任何线性变换，直接令 Q=K=V=X（现实里会各自过一层线性投影，这里先别管）。\n",
    "\n",
    "这样你能看到：每个词的位置会按相似度从其他词那里“取信息”（加权平均）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab19a071-daf8-4b79-a1a7-e02a97d688c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_attention_minimal(X):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "    X: np.ndarray shape [T, D], one sequence of T vectors (each vector is D-dimensional)\n",
    "\n",
    "    output:\n",
    "    Y: np.ndarray shape [T, D], self attention output, every position i is a new representation from weight averaged all positions\n",
    "\n",
    "    how it works:\n",
    "    for every i:\n",
    "        socres[i, j] = X[i] X[j]\n",
    "        weights[i] = softmax(socres[i])\n",
    "        Y[i] = sum(weights[i, j] * X[j]) over j\n",
    "    \"\"\"\n",
    "\n",
    "    T, D = X.shape\n",
    "    Y = np.zeros_like(X)\n",
    "    for i in range(T):\n",
    "        scores = X @ X[i]\n",
    "        weights = softmax(scores)\n",
    "        Y[i] = weighted_average(X, weights)\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63a03c74-4300-4094-8756-1b1b387657bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入 X 形状: (4, 3)\n",
      "输出 Y 形状: (4, 3)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "X = np.random.randn(4, 3).astype(np.float32)  # T=4 词，D=3 维\n",
    "Y = self_attention_minimal(X)\n",
    "print(\"输入 X 形状:\", X.shape)\n",
    "print(\"输出 Y 形状:\", Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "573d3b93-cf98-4099-86b7-c4fd6ad3c666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.7640524 ,  0.4001572 ,  0.978738  ],\n",
       "       [ 2.2408931 ,  1.867558  , -0.9772779 ],\n",
       "       [ 0.95008844, -0.1513572 , -0.10321885],\n",
       "       [ 0.41059852,  0.14404356,  1.4542735 ]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8556d5de-a4d8-49dd-a7e9-92f042eafea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.7975295 ,  0.85911125,  0.3104185 ],\n",
       "       [ 2.238525  ,  1.8615676 , -0.9702689 ],\n",
       "       [ 1.7368875 ,  0.9578309 , -0.05566131],\n",
       "       [ 1.0923121 ,  0.30132565,  1.0670953 ]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c622301-0828-4135-9bae-c096462209eb",
   "metadata": {},
   "source": [
    "# 2. Almost replay of part 1 on NumPy: Weighted Average -> One-shot Attention -> Self-Attention (Q=K=V=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4180062-4737-44e3-b6e3-ab29ee33eab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_average(values, weights):\n",
    "    \"\"\"\n",
    "    Inputs: \n",
    "    values [N,D]\n",
    "    weights [N]\n",
    "    \"\"\"\n",
    "    w = weights / (weights.sum() + 1e-12)\n",
    "    return (w[:, None] * values).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01677852-ea1c-4ce9-a6e5-b3ea9a068ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_np(x):\n",
    "    \"\"\"\n",
    "    x shape [N]\n",
    "    \"\"\"\n",
    "    x = x - x.max()\n",
    "    e = np.exp(x)\n",
    "    return e / (e.sum() + 1e-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0d46e91-2c2e-49f9-8c85-f2eb96364c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_once_numpy(Q, K, V, scale, mask):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    Q: [D] single query\n",
    "    K: [N, D], N keys\n",
    "    V: [N, Dv], N values\n",
    "    scale: bool, if do 1/sqrt(D)\n",
    "    mask: shape[N] dtype=bool, if True, that key's position is masked, not participate in attention\n",
    "\n",
    "    Outputs:\n",
    "    out: [Dv] attention output (weighted average of V)\n",
    "    weights: [N] the weights (sum == 1)\n",
    "    scores: [N] score (before softmax)\n",
    "    \"\"\"\n",
    "\n",
    "    scores = K @ Q\n",
    "    if scale:\n",
    "        scores = scores / np.sqrt(Q.shape[0])\n",
    "\n",
    "    if mask is not None:\n",
    "        scores = scores.copy()\n",
    "        scores[mask] = -1e9\n",
    "    weights = softmax_np(scores)\n",
    "    out = (weights[:, None] * V).sum(axis=0)\n",
    "    return out, weights, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c309cc4d-fbc3-4e8f-b3ca-33727bd93d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_attention_minimal_numpy(X, scale):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    X [T, D], one sequence has T D-d vector (Q = K = V)\n",
    "\n",
    "    Outputs:\n",
    "    T [T, D], attention output\n",
    "\n",
    "    Here the purpose is to show how attention works, very very simple case of self-attention that Q=K=V=X, real cases that will do projection\n",
    "    \"\"\"\n",
    "\n",
    "    T, D = X.shape\n",
    "    Y = np.zeros_like(X)\n",
    "    for i in range(T):\n",
    "        q = X[i]\n",
    "        out, _, _, = attention_once_numpy(q, X, X, scale=scale, mask=None)\n",
    "        Y[i] = out\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f57d08ac-bfbf-4844-beff-e3839a30e572",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo_numpy_block():\n",
    "    print(\"\\n[Demo] 1) NumPy attention basics\")\n",
    "    # Values & weights demo\n",
    "    V = np.array([[10., 0.], [0., 10.], [5., 5.]], dtype=np.float32)  # [3,2]\n",
    "    w = np.array([0.7, 0.2, 0.1], dtype=np.float32)                   # [3]\n",
    "    print(\"weighted_average:\", weighted_average(V, w))  # ~[7., 3.]\n",
    "\n",
    "    # One-shot attention\n",
    "    Q = np.array([1., 0.], dtype=np.float32)\n",
    "    K = np.array([[1., 0.], [0.7, 0.2], [-1., 0.]], dtype=np.float32)  # [3,2]\n",
    "    out, weights, scores = attention_once_numpy(Q, K, V, scale=True, mask=None)\n",
    "    print(\"scores:\", np.round(scores, 3), \"weights:\", np.round(weights, 3), \"out:\", np.round(out, 3))\n",
    "\n",
    "    # Self-attention (Q=K=V=X)\n",
    "    X = np.array([[1.0, 0.0],\n",
    "                  [0.8, 0.2],\n",
    "                  [0.1, 0.9]], dtype=np.float32)  # [\"i\",\"love\",\"nlp\"] toy vectors\n",
    "    Y = self_attention_minimal_numpy(X, scale=True)\n",
    "    print(\"X:\\n\", np.round(X, 3), \"\\nY:\\n\", np.round(Y, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6c2f5afe-6d0f-4bbc-bdc1-c7ba0363a8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Demo] 1) NumPy attention basics\n",
      "weighted_average: [7.5 2.5]\n",
      "scores: [ 0.707  0.495 -0.707] weights: [0.487 0.394 0.118] out: [5.466 4.534]\n",
      "X:\n",
      " [[1.  0. ]\n",
      " [0.8 0.2]\n",
      " [0.1 0.9]] \n",
      "Y:\n",
      " [[0.729 0.271]\n",
      " [0.693 0.307]\n",
      " [0.545 0.455]]\n"
     ]
    }
   ],
   "source": [
    "demo_numpy_block()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "af335080-d223-4980-979e-59aa049a6671",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1.0, 0.0],\n",
    "                  [0.8, 0.2],\n",
    "                  [0.1, 0.9]], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fbe1ae29-d7fd-4dd4-a342-42ebb83a03f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = (X @ X.T) / np.sqrt(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6b13a444-0761-4715-9204-12a8455d8567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.70710677, 0.56568545, 0.07071068],\n",
       "       [0.56568545, 0.48083267, 0.18384776],\n",
       "       [0.07071068, 0.18384776, 0.57982755]], dtype=float32)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "91cf5aa4-3044-4850-a060-9ad0037fa6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [softmax_np(t) for t in scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8167e701-4d58-4ca8-a51b-0b695528114a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.4171325 , 0.3621225 , 0.22074491], dtype=float32),\n",
       " array([0.38443005, 0.3531557 , 0.2624142 ], dtype=float32),\n",
       " array([0.26429808, 0.29595715, 0.43974477], dtype=float32)]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "aeadaa0e-b2da-48f1-af35-28ee97091933",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = [(weight[:, None] * X).sum(axis=0) for weight in weights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bc70db4b-54be-44d2-adaf-2885780b97db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.72890496, 0.27109492], dtype=float32),\n",
       " array([0.69319606, 0.3068039 ], dtype=float32),\n",
       " array([0.5450383 , 0.45496172], dtype=float32)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "397b3769-decc-4399-930b-28d9b0a93831",
   "metadata": {},
   "outputs": [],
   "source": [
    "out, _, _ = attention_once_numpy(X[2], X, X, True, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bf262ed2-1806-471e-9613-546cb8e92dbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5450383 , 0.45496172], dtype=float32)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "170356d4-07e0-4284-a916-2041f039c830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.72890496 0.27109492]\n",
      "[0.69319606 0.3068039 ]\n",
      "[0.5450383  0.45496172]\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    q = X[i]\n",
    "    scores = X @ q / np.sqrt(2)\n",
    "    weights = softmax_np(scores)\n",
    "    out = (weights[:, None] * X).sum(axis=0)\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "17a19c43-60a6-4df3-8d3d-bc3d7bbb83fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = [softmax_np(t) for t in X @ X.T / np.sqrt(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9e44bf9d-1821-4b91-afea-bd5ee018733a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.4171325 , 0.3621225 , 0.22074491], dtype=float32),\n",
       " array([0.38443005, 0.3531557 , 0.2624142 ], dtype=float32),\n",
       " array([0.26429808, 0.29595715, 0.43974477], dtype=float32)]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ca6b0665-c879-493c-b24e-e7a29c224c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = [(weight[:, None] * X).sum(axis=0) for weight in W]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ffed995a-bad6-42b0-af6d-137c9c898e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.72890496, 0.27109492], dtype=float32),\n",
       " array([0.69319606, 0.3068039 ], dtype=float32),\n",
       " array([0.5450383 , 0.45496172], dtype=float32)]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd77126b-5140-4e16-bf0d-604bf41e75e0",
   "metadata": {},
   "source": [
    "# 3. Single head self attention in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2b4f863b-3f92-42f7-90e1-5c0ec29825b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttentionSimple(nn.Module):\n",
    "    \"\"\"\n",
    "    Single head attention (can choose linear project or not), and support padding/causal mask\n",
    "    - if use_projection False, Q=K=V=x\n",
    "    - if use_projection True, Q=xWq, K=xWk, V=xWv\n",
    "\n",
    "    Inputs (foward)\n",
    "    x: [B, T, d_model]\n",
    "    key_padding_mask: [B, T]\n",
    "    causal: bool\n",
    "\n",
    "    Outputs\n",
    "    y: [B, T, d_model] here d_v = d_model\n",
    "    attn: [B, T, T] attention weight, every sample a TxT graph\n",
    "\n",
    "    Purpose:\n",
    "    scores = QK^T/sqrt(d), mask->softmax->weights, weightsxV->output\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model=32, use_projection=False, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.use_proj = use_projection\n",
    "        if use_projection:\n",
    "            self.Wq = nn.Linear(d_model, d_model, bias=False)\n",
    "            self.Wk = nn.Linear(d_model, d_model, bias=False)\n",
    "            self.Wv = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, key_padding_mask=None, causal=False):\n",
    "        B, T, D = x.shape\n",
    "        if self.use_proj:\n",
    "            Q, K, V = self.Wq(x), self.Wk(x), self.Wv(x)\n",
    "        else:\n",
    "            Q = K = V = x\n",
    "\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(D) #K from [B,T,D] transpose last two dimension -> [B, D, T]\n",
    "        #score is [B, T, T], batch matmul\n",
    "        if key_padding_mask is not None:\n",
    "            scores = scores.masked_fill(key_padding_mask[:, None, :], float(\"-inf\")) #mask [B,T] -> [B, 1, T] broadcast to [B, T, T]\n",
    "\n",
    "        if causal:\n",
    "            # 上三角（strict）为 -inf\n",
    "            causal_mask = torch.triu(torch.ones(T, T, dtype=torch.bool, device=x.device), diagonal=1) #mask [T, T]\n",
    "            scores = scores.masked_fill(causal_mask.unsqueeze(0), float(\"-inf\")) # unsqueeze into [1, T, T], broadcast to [B,T,T]\n",
    "\n",
    "        attn = F.softmax(scores, dim=-1) # [B,T,T]\n",
    "        attn = self.dropout(attn)\n",
    "        y = torch.matmul(attn, V) # [B,T,T] @ [B, T, D] get [B, T,D]\n",
    "        return y, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0d9b17e9-1741-408b-82be-1f15b3dc42c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo_torch_selfattn():\n",
    "    print(\"\\n[Demo] 2) PyTorch SelfAttentionSimple (with masks)\")\n",
    "    torch.manual_seed(SEED)\n",
    "    B, T, D = 2, 5, 8\n",
    "    x = torch.randn(B, T, D)\n",
    "\n",
    "    # Padding mask: batch0 最后两位是 pad，batch1 最后三位是 pad\n",
    "    key_pad = torch.tensor([[False, False, False, True, True],\n",
    "                            [False, False, True,  True, True]])\n",
    "\n",
    "    sa = SelfAttentionSimple(d_model=D, use_projection=False)\n",
    "    y, attn = sa(x, key_padding_mask=key_pad, causal=False)\n",
    "    print(\"y shape:\", y.shape, \"attn shape:\", attn.shape)  # [B,T,D], [B,T,T]\n",
    "\n",
    "    # 再看 causal（因果）自注意力\n",
    "    y2, attn2 = sa(x, key_padding_mask=None, causal=True)\n",
    "    print(\"causal attn upper-triangle ~0? row sums:\", attn2.sum(-1))  # 每行和≈1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "21fc48c6-b5f5-4a45-973b-e5bbf59d4108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Demo] 2) PyTorch SelfAttentionSimple (with masks)\n",
      "y shape: torch.Size([2, 5, 8]) attn shape: torch.Size([2, 5, 5])\n",
      "causal attn upper-triangle ~0? row sums: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "demo_torch_selfattn()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127c04d6-8e63-4f8d-920f-a2b3094ce5c4",
   "metadata": {},
   "source": [
    "# 4. nn.MultiheadAttention in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4d56b745-2a98-41f3-99bb-5c6be3ddf759",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_causal_mask(T, device=None):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    T\n",
    "\n",
    "    Outputs:\n",
    "    attn_mask: [T,T], upper triangle is -inf\n",
    "    \"\"\"\n",
    "    m = torch.zeros(T, T, dtype=torch.float32, device=device)\n",
    "    m = m.masked_fill(torch.triu(torch.ones_like(m), diagonal=1).bool(), float(\"inf\"))\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ab82fffd-561e-414b-be4a-d36c985dfebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo_torch_mha_api():\n",
    "    print(\"\\n[Demo] 3) nn.MultiheadAttention API (batch_first=True)\")\n",
    "    torch.manual_seed(SEED)\n",
    "    B, T, D, H = 2, 5, 16, 4\n",
    "    x = torch.randn(B, T, D)\n",
    "\n",
    "    # key_padding_mask: True=pad\n",
    "    key_padding_mask = torch.tensor([[False, False, False, True, True],\n",
    "                                     [False, False, True,  True, True]])\n",
    "\n",
    "    attn = nn.MultiheadAttention(embed_dim=D, num_heads=H, batch_first=True, dropout=0.0)\n",
    "    # Self-attention: Q=K=V=x\n",
    "    y, w = attn(x, x, x,\n",
    "                key_padding_mask=key_padding_mask,\n",
    "                need_weights=True,              # 请求权重\n",
    "                average_attn_weights=False)     # 每个头各自的权重\n",
    "    print(\"output:\", y.shape, \"weights:\", w.shape)  # [B,T,D], [B,H,T,T]\n",
    "\n",
    "    # Decoder self-attention with causal mask\n",
    "    attn_mask = make_causal_mask(T, device=x.device)  # [T,T]\n",
    "    y2, w2 = attn(x, x, x, attn_mask=attn_mask,\n",
    "                  need_weights=True, average_attn_weights=False)\n",
    "    print(\"causal output:\", y2.shape, \"weights:\", w2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "af67fdc6-2949-4a3d-aa8b-3bc565d78641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Demo] 3) nn.MultiheadAttention API (batch_first=True)\n",
      "output: torch.Size([2, 5, 16]) weights: torch.Size([2, 4, 5, 5])\n",
      "causal output: torch.Size([2, 5, 16]) weights: torch.Size([2, 4, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "demo_torch_mha_api()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2043241d-a07e-4d88-bcfc-539ccab55526",
   "metadata": {},
   "source": [
    "# 5. Minimal Encoder Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4c6224d8-f5e6-4732-adfc-4eb09bb54dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFFN(nn.Module):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    x [B, T, d_model]\n",
    "\n",
    "    Outputs:\n",
    "    y [B, T, d_model]\n",
    "\n",
    "    Purpose: Linear(d->4d) -> GELU -> Dropout -> Linear(4d->d)\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d4dbb160-9901-4be5-bf48-e12c5e72ca8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    x [B, T, d_model]\n",
    "    key_padding_mask [B, T]\n",
    "\n",
    "    Outputs:\n",
    "    y [B, T, d_model]\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model=128, num_heads=4, d_ff=512, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.ln1 = nn.LayerNorm(d_model)\n",
    "        self.mha = nn.MultiheadAttention(d_model, num_heads, batch_first=True, dropout=dropout)\n",
    "        self.ln2 = nn.LayerNorm(d_model)\n",
    "        self.ffn = PositionwiseFFN(d_model, d_ff, dropout)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, key_padding_mask=None):\n",
    "        h = self.ln1(x)\n",
    "        attn_out, _ = self.mha(h, h, h, key_padding_mask=key_padding_mask, need_weights=False)\n",
    "        x = x + self.drop(attn_out) #residual\n",
    "        h = self.ln2(x)\n",
    "        x = x + self.drop(self.ffn(h))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8477d0e0-7f86-4c17-bdf9-f5748fa81474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo_encoder_block():\n",
    "    print(\"\\n[Demo] 4) EncoderBlock forward\")\n",
    "    torch.manual_seed(SEED)\n",
    "    B, T, D = 2, 6, 32\n",
    "    x = torch.randn(B, T, D)\n",
    "    pad = torch.tensor([[False, False, False, False, True,  True],\n",
    "                        [False, False, False, True,  True,  True]])\n",
    "    block = EncoderBlock(d_model=D, num_heads=4, d_ff=128, dropout=0.1)\n",
    "    y = block(x, key_padding_mask=pad)\n",
    "    print(\"encoder block output:\", y.shape)  # [B,T,D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9b72c6e2-c874-4927-8704-d4ecbfb2f1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Demo] 4) EncoderBlock forward\n",
      "encoder block output: torch.Size([2, 6, 32])\n"
     ]
    }
   ],
   "source": [
    "demo_encoder_block()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbc668d-4c08-4dc6-87cc-a7530cb70737",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
