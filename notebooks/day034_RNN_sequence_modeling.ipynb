{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cd9e3df-befe-45c7-bdb1-daec1bfa6604",
   "metadata": {},
   "source": [
    "# 1. Numpy RNN Cell step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2211fff1-545d-4d19-8dd1-9ba78883b303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42ae09fa-eaf0-47d9-a9dd-ce7f1d664053",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnncell_step(x_t, h_prev, Wx, Wh, bh):\n",
    "    \"\"\"\n",
    "    input:\n",
    "    x_t: [B, D_in]\n",
    "    h_prev: [B, H]\n",
    "    Wx: [D_in, H]\n",
    "    Wh: [H, H]\n",
    "    bh: [H]\n",
    "    output:\n",
    "    h_t: [B, H]\n",
    "    \"\"\"\n",
    "    h_t = np.tanh(x_t @ Wx + h_prev @ Wh + bh)\n",
    "    return h_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe3653a7-e7b0-4665-a6a5-e6f0e508580e",
   "metadata": {},
   "outputs": [],
   "source": [
    "B, T, D_in, H = 2, 5, 4, 8\n",
    "np.random.seed(42)\n",
    "X = np.random.randn(B, T, D_in).astype(np.float32)\n",
    "Wx = np.random.randn(D_in, H).astype(np.float32)\n",
    "Wh = np.random.randn(H, H).astype(np.float32)\n",
    "bh = np.zeros(H, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef9a8144-d95a-477c-9a1f-534759a4a847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H_all shape (2, 5, 8)\n"
     ]
    }
   ],
   "source": [
    "h = np.zeros((B, H), dtype=np.float32)\n",
    "Hs = []\n",
    "for t in range(T):\n",
    "    h = rnncell_step(X[:, t, :], h, Wx, Wh, bh) #time \n",
    "    Hs.append(h)\n",
    "H_all = np.stack(Hs, axis=1) # [B, T, H]\n",
    "print(f\"H_all shape {H_all.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d11afe1-f8e7-4224-9bb8-f7f43c20caf0",
   "metadata": {},
   "source": [
    "# 2. PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619d3b30-d3dc-42d3-a6b0-31c7801c70fd",
   "metadata": {},
   "source": [
    "## 2.1 char level LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47542ae8-838c-419c-a8f9-fd556247a3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn, torch.nn.utils as nn_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7acb433f-bfb6-48e3-9b54-3d286efffe0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"hello world! \" * 200\n",
    "vocab = sorted(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84920145-8a67-450f-a1a6-96000ea6a418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ', '!', 'd', 'e', 'h', 'l', 'o', 'r', 'w']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed9872b6-7ef0-4124-b647-a121f2b28ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = {c:i for i, c in enumerate(vocab)}\n",
    "itos = {i:c for c, i in stoi.items()}\n",
    "ids = torch.tensor([stoi[c] for c in text], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f5d9b23-f732-48d5-af4b-e344c3d119f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 3, 5, 5, 6, 0, 8, 6, 7, 5, 2, 1, 0, 4, 3, 5, 5, 6, 0, 8, 6, 7, 5, 2,\n",
       "        1, 0, 4, 3, 5, 5])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "633060fe-ace0-4e84-83f9-695cf6d25745",
   "metadata": {},
   "outputs": [],
   "source": [
    "B, T = 16, 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a59d6dd-f8cc-4307-8a09-4a5dab9a855a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch():\n",
    "    ix = torch.randint(0, len(ids) - T - 1, (B,)) #randint(low, high, size)\n",
    "    x = torch.stack([ids[i:i+T] for i in ix])\n",
    "    y = torch.stack([ids[i+1:i+T+1] for i in ix])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f322155c-f0ea-4835-80f7-d2d77458e87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharRNNCellLM(nn.Module):\n",
    "    def __init__(self, vocab_size, d_emb=32, hidden=64):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, d_emb)\n",
    "        self.cell = nn.RNNCell(d_emb, hidden, nonlinearity=\"tanh\")\n",
    "        self.proj = nn.Linear(hidden, vocab_size)\n",
    "\n",
    "    def forward(self, x): #x: [B,T]\n",
    "        B, T = x.shape\n",
    "        h = torch.zeros(B, self.cell.hidden_size, device=x.device)\n",
    "        logits_all = []\n",
    "        for t in range(T):\n",
    "            e_t = self.emb(x[:, t]) # [B, d_emb]\n",
    "            h = self.cell(e_t, h) #[B, H]\n",
    "            logits_all.append(self.proj(h)) #[B,V]\n",
    "        return torch.stack(logits_all, dim=1) #[B,T,V]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2067b0d2-dc93-4c52-a113-7d1c058b75c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\")\n",
    "model = CharRNNCellLM(len(vocab)).to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=3e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac944814-3819-4d0b-9d27-754c42badcd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step 0] loss=2.278\n",
      "[step 50] loss=0.038\n",
      "[step 100] loss=0.027\n",
      "[step 150] loss=0.016\n",
      "[step 200] loss=0.024\n"
     ]
    }
   ],
   "source": [
    "for step in range(201):\n",
    "    x, y = get_batch()\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    logits = model(x)\n",
    "    loss = loss_fn(logits.reshape(-1, logits.size(-1)), y.reshape(-1))\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    nn_utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  #gradient clipping\n",
    "    opt.step()\n",
    "    if step % 50 == 0:\n",
    "        print(f\"[step {step}] loss={loss.item():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef4168d0-3cb2-4c71-b172-555162684157",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check after training\n",
    "\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e93392b8-f8df-406c-af5d-8f04828346ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_char_lm_torch(model, stoi, itos, prompt=\"hel\", max_new_tokens=100, temperature=1.0, top_k=None, device=\"mps\"):\n",
    "    \"\"\"\n",
    "    model: the trained CharRNNCellLM\n",
    "    stoi/itos: string<->id \n",
    "    prompt: starting chars\n",
    "    temperature: temperature sampling，>1 更发散，<1 更确定\n",
    "    top_k: 只在概率最高的 k 个字符里采样（None 关闭）\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    #1) prompt preheat h\n",
    "    h = torch.zeros(1, model.cell.hidden_size, device=device)\n",
    "    for ch in prompt[:-1]:\n",
    "        idx = torch.tensor([stoi[ch]], device=device)\n",
    "        e = model.emb(idx)\n",
    "        h = model.cell(e, h)\n",
    "\n",
    "    #2) starting from last char of prompt and generating\n",
    "    last_idx = torch.tensor([stoi[prompt[-1]]], device=device)\n",
    "    generated = list(prompt)\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        e = model.emb(last_idx)\n",
    "        h = model.cell(e, h)\n",
    "        logits = model.proj(h)\n",
    "        logits = logits / max(temperature, 1e-8)\n",
    "\n",
    "        if top_k is not None:\n",
    "            vals, inds = torch.topk(logits, k=top_k, dim=-1)\n",
    "            probs = F.softmax(vals, dim=-1)\n",
    "            nxt = inds[0, torch.multinomial(probs[0], 1)]\n",
    "        else:\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            nxt = torch.multinomial(probs[0], 1)[0]\n",
    "\n",
    "        generated.append(itos[int(nxt)])\n",
    "        last_idx = nxt.view(1)\n",
    "\n",
    "    return \"\".join(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e76c7748-4060-4d1f-8d39-32ce00585106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[PyTorch sample]\n",
      " hello world! hello world! hello world! hello world! hello world! hello world! hello world! hello world! hello world! hello \n"
     ]
    }
   ],
   "source": [
    "sample = generate_char_lm_torch(\n",
    "    model, stoi, itos, \n",
    "    prompt=\"hel\", max_new_tokens=120, \n",
    "    temperature=0.8, top_k=5, device=device\n",
    ")\n",
    "print(\"\\n[PyTorch sample]\\n\", sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7e7769-5c90-4fa6-be30-298899cfa1b0",
   "metadata": {},
   "source": [
    "## 2.2 Embedding -> RNN -> Last state -> Linear for sequence classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb11dd19-1c36-44a8-a7c0-26762b6133d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"this movie is great and excellent\",\n",
    "    \"fantastic film wonderful direction\",\n",
    "    \"good plot amazing soundtrack\",\n",
    "    \"touching story strong performances\",\n",
    "    \"brilliant engaging narrative\",\n",
    "    \"bad pacing awful movie\",\n",
    "    \"boring film dull characters\",\n",
    "    \"terrible editing horrible dialogue\",\n",
    "    \"predictable script poor scenes\",\n",
    "    \"unwatchable messy scenes weak plot\",\n",
    "]\n",
    "labels = torch.tensor([1,1,1,1,1, 0,0,0,0,0], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2d909b55-6d8d-44cf-a90c-6eac43a2e9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "90875d51-08b9-4512-b6c9-4b3a50bb079b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tok(s):\n",
    "    return re.findall(r\"[a-z]+\", s.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ae1b8e94-5cb9-4e48-85cc-d681c1b0524d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted({w for s in corpus for w in tok(s)})\n",
    "stoi = {w:i+1 for i, w in enumerate(vocab)}\n",
    "pad = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e9566c2a-c015-4d1c-8df0-660b30b8788c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(s, T=10):\n",
    "    ids = [stoi.get(w, 0) for w in tok(s)][:T]\n",
    "    return torch.tensor(ids + [pad] * (T - len(ids)), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "98829958-01b2-4afa-932f-b5f1aa5d51f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.stack([encode(s) for s in corpus]) #[N, T]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4f76274e-5c12-466a-87c0-3540e5a58ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentRNN(nn.Module):\n",
    "    def __init__(self, V, d_emb=64, hidden=64, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(V + 1, d_emb, padding_idx=pad)\n",
    "        self.rnn = nn.RNN(d_emb, hidden, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        e = self.emb(x) # [B,T,d]\n",
    "        out, hT = self.rnn(e) # hT: [1, B, H]\n",
    "        return self.fc(hT.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "54437fcc-fab0-421c-98cd-e5ce53563be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentRNN(len(vocab)).to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=3e-3)\n",
    "ce = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a98a614c-0422-4f59-81df-49c0fe042757",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.to(device)\n",
    "labels = labels.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1c5599c9-db11-4429-8449-1d0ce426bd74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ep 0] loss=0.705 acc=0.50\n",
      "[ep 10] loss=0.026 acc=1.00\n",
      "[ep 20] loss=0.001 acc=1.00\n",
      "[ep 30] loss=0.000 acc=1.00\n",
      "[ep 40] loss=0.000 acc=1.00\n"
     ]
    }
   ],
   "source": [
    "for ep in range(50):\n",
    "    logits = model(X)\n",
    "    loss = ce(logits, labels)\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    opt.step()\n",
    "    if ep % 10 == 0:\n",
    "        acc = (logits.argmax(1) == labels).float().mean().item()\n",
    "        print(f\"[ep {ep}] loss={loss.item():.3f} acc={acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "54b09118-0fcf-4c3c-bb2a-5fda4bbf679b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Eval] Train accuracy = 1.000\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits_tr = model(X)                # [N, num_classes]\n",
    "    y_pred_tr = logits_tr.argmax(1)\n",
    "    train_acc  = (y_pred_tr == labels).float().mean().item()\n",
    "print(f\"[Eval] Train accuracy = {train_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fef80f64-a66d-450a-b8c1-ec8ee53ab094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Predict] 'this film is wonderful and touching' -> POSITIVE  probs=[0.27460364 0.72539634]\n",
      "[Predict] 'awful boring movie with dull characters' -> POSITIVE  probs=[7.4766442e-04 9.9925226e-01]\n"
     ]
    }
   ],
   "source": [
    "label_names = {0: \"NEGATIVE\", 1: \"POSITIVE\"}  # 按你labels的定义来\n",
    "def predict(texts, T=10, return_proba=True):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    X_new = torch.stack([encode(s, T=T) for s in texts]).to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(X_new)                         # [B, 2]\n",
    "        probs  = torch.softmax(logits, dim=1).cpu()   # [B, 2]\n",
    "        pred   = probs.argmax(1).numpy()\n",
    "    if return_proba:\n",
    "        return pred, probs.numpy()\n",
    "    return pred\n",
    "\n",
    "samples = [\n",
    "    \"this film is wonderful and touching\",\n",
    "    \"awful boring movie with dull characters\"\n",
    "]\n",
    "pred, prob = predict(samples, T=10, return_proba=True)\n",
    "for s, p, pr in zip(samples, pred, prob):\n",
    "    print(f\"[Predict] {s!r} -> {label_names[int(p)]}  probs={pr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4f7c7a-b6fe-43cf-869e-9939d1a86000",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
