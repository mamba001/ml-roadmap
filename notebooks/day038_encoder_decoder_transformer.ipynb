{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11ea6c60-6da6-4a8b-aa8d-5bc01a826565",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52cc9bb7-4490-4cab-a8f5-e085719be47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "DEVICE = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc9270d-a012-4baf-97c6-39c1ff9a3779",
   "metadata": {},
   "source": [
    "# 1. Mask and helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5841a120-e9b1-470e-81ee-0b7779957434",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pad_mask(ids, pad_id):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    ids: [B, T]\n",
    "    pad_id: int\n",
    "\n",
    "    Outputs:\n",
    "    pad_mask: [B, T]\n",
    "    \n",
    "    \"\"\"\n",
    "    return ids.eq(pad_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fad46f42-5d43-46a2-a314-06de467fad75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_causal_mask(T, device=None):\n",
    "    \"\"\"\n",
    "    Inputs\n",
    "    ------\n",
    "    T : int  (target length)\n",
    "\n",
    "    Outputs\n",
    "    -------\n",
    "    causal_mask : FloatTensor [T, T]\n",
    "        Upper triangle (strict) is -inf; others 0.\n",
    "        For nn.MultiheadAttention(attn_mask) with batch_first=True.\n",
    "\n",
    "    Purpose\n",
    "    -------\n",
    "    Prevent decoder positions from attending to future tokens.\n",
    "    upper triangle are -inf, all other positions are 0\n",
    "    \"\"\"\n",
    "    m = torch.zeros(T, T, dtype=torch.float32, device=device)\n",
    "    m = m.masked_fill(torch.triu(torch.ones_like(m), diagonal=1).bool(), float('-inf'))\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf1c2b5-a745-4e9b-b80b-9646ce80c36b",
   "metadata": {},
   "source": [
    "# 2. Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4953699d-6305-4af7-977a-af7b0b6c32bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"\n",
    "    Sinusoidal PE added to token embeddings\n",
    "    给词向量添加正弦位置编码\n",
    "\n",
    "    Inputs:\n",
    "    x: [B, T, d_model]\n",
    "\n",
    "    Outputs:\n",
    "    x_pe: [B, T, d_model]\n",
    "\n",
    "    add deterministic position information since attention is order-agnostic\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, max_len=4096, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        pe = torch.zeros(max_len, d_model, dtype=torch.float32) \n",
    "        # create an empty pe of shape [max_len, d_model], every row ==> correspond a position, every column ==> sin or cos value of a freq\n",
    "        \n",
    "        pos = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1) \n",
    "        #[L,1], pos is 0, 1, 2,...,max_len-1\n",
    "        \n",
    "        div = torch.exp(torch.arange(0, d_model, 2, dtype=torch.float32) * (-math.log(10000.0) / d_model))\n",
    "        # div[i] = 10000^(- (2i/d_model)), the bigger i, the smaller value, shape is [d_model/2]\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(pos * div) # even --> sin\n",
    "        pe[:, 1::2] = torch.cos(pos * div) # odd --> cos\n",
    "        self.register_buffer(\"pe\", pe.unsqueeze(0), persistent=False) #[1, L, d]\n",
    "        #register_buffer：告诉 PyTorch 这是个常量（不会被优化器更新），但会跟着 model.to(device) 移动到显卡/CPU。\n",
    "        #persistent=False，表示不会写进 state_dict()。\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, D = x.shape\n",
    "        return self.dropout(x + self.pe[:, :T, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d212638-f810-4a88-901c-55e6783f7c9f",
   "metadata": {},
   "source": [
    "# 3. FFN, Encoder, and Decoder block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e0a549a-cc60-4543-af74-36a8d12e4455",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFFN(nn.Module):\n",
    "    \"\"\"\n",
    "    Position-wise feed-forward network\n",
    "\n",
    "    inputs:\n",
    "    x [B, T, d_modl]\n",
    "\n",
    "    outputs:\n",
    "    y [B, T, d_model]\n",
    "\n",
    "    two layer MLP (per time step): linear (d->d_ff) -> GELU -> Dropout -> Linear(d_ff->d)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "13a6ea47-5b90-4ec1-bf81-5f996630df31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    one transformer encoder layer (pre-LN)\n",
    "\n",
    "    inputs:\n",
    "    x: [B, T_src, d_model]\n",
    "    src_key_padding_mask: [B, T_src] or None\n",
    "\n",
    "    outputs:\n",
    "    y: [B, T_src, d_model]\n",
    "\n",
    "    LN → 自注意力 → 残差，然后 LN → FFN → 残差\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.ln1 = nn.LayerNorm(d_model)\n",
    "        self.mha = nn.MultiheadAttention(d_model, num_heads, dropout=dropout, batch_first=True)\n",
    "        self.ln2 = nn.LayerNorm(d_model)\n",
    "        self.ffn = PositionwiseFFN(d_model, d_ff, dropout)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, src_key_padding_mask):\n",
    "        # first layer norm\n",
    "        h = self.ln1(x)\n",
    "        # multihead attention: Q=K=V=h\n",
    "        attn_out, _ = self.mha(h, h, h, key_padding_mask=src_key_padding_mask, need_weights=False)\n",
    "        # residual + dropout\n",
    "        x = x + self.drop(attn_out)\n",
    "        # layer norm\n",
    "        h = self.ln2(x)\n",
    "        # feedforward + dropout + residual\n",
    "        x = x + self.drop(self.ffn(h))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25427b03-e2f2-46fb-bc06-29fea1cf7088",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    one transformer decoder layer (pre-LN)\n",
    "\n",
    "    inputs:\n",
    "    y: [B, T_tgt, d_model]\n",
    "    enc_out: [B, T_src, d_model]\n",
    "    tgt_key_padding_mask: [B, T_tgt] or None\n",
    "    tgt_causal_mask: [T_tgt, T_tgt] or None\n",
    "    src_key_padding_mask: [B, T_src] or None\n",
    "\n",
    "    outputs:\n",
    "    y_out: [B, T_tgt, d_model]\n",
    "\n",
    "\n",
    "    解码器自注意力（因果遮罩） → 交叉注意力（看编码器输出） → FFN，每段前 Pre-LN，段后做残差。\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.ln1 = nn.LayerNorm(d_model)\n",
    "        self.self_attn = nn.MultiheadAttention(d_model, num_heads, dropout=dropout, batch_first=True)\n",
    "        self.ln2 = nn.LayerNorm(d_model)\n",
    "        self.cross_attn = nn.MultiheadAttention(d_model, num_heads, dropout=dropout, batch_first=True)\n",
    "        self.ln3 = nn.LayerNorm(d_model)\n",
    "        self.ffn = PositionwiseFFN(d_model, d_ff, dropout)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, y, enc_out,\n",
    "                tgt_key_padding_mask,\n",
    "                tgt_causal_mask,\n",
    "                src_key_padding_mask):\n",
    "        # Masked self-attn (causal + tgt padding), must be causal, cannot see future\n",
    "        h = self.ln1(y)\n",
    "        sa_out, _ = self.self_attn(h, h, h,\n",
    "                                   attn_mask=tgt_causal_mask,\n",
    "                                   key_padding_mask=tgt_key_padding_mask,\n",
    "                                   need_weights=False)\n",
    "        # residual + dropout\n",
    "        y = y + self.drop(sa_out)\n",
    "        # Cross-attn over encoder outputs (mask pads on encoder keys) Q=decoder, K, V=encoder\n",
    "        h = self.ln2(y)\n",
    "        ca_out, _ = self.cross_attn(h, enc_out, enc_out,\n",
    "                                    key_padding_mask=src_key_padding_mask,\n",
    "                                    need_weights=False)\n",
    "        y = y + self.drop(ca_out)\n",
    "        # FFN\n",
    "        h = self.ln3(y)\n",
    "        y = y + self.drop(self.ffn(h))\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf3269d-c8f4-4ae9-95ba-da46d1952eb5",
   "metadata": {},
   "source": [
    "# 4. Full encoder, decoder, and seq2seq model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9e574657-13cb-410b-bb49-32e7457bfa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder: embedding + posenc + N layers encoderblock\n",
    "    inputs: src_ids [B, T_src]\n",
    "            src_key_padding_mask [B, T_src]\n",
    "\n",
    "    outputs: enc_out [B, T_src, d_model]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, d_model, num_layers, num_heads, d_ff, pad_id, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, d_model, padding_idx=pad_id)\n",
    "        self.pe = PositionalEncoding(d_model, dropout=dropout)\n",
    "        self.layers = nn.ModuleList([EncoderBlock(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "\n",
    "    def forward(self, src_ids, src_key_padding_mask):\n",
    "        x = self.pe(self.emb(src_ids))\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, src_key_padding_mask)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ba1cd503-c85c-45c0-b7ce-dfad9c917983",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    decoder: embedding + posenc + N layers decoderblock\n",
    "    inputs: tgt_in [B, T_tgt]\n",
    "            enc_out [B, T_src, d]\n",
    "            tgt_key_padding_mask [B, T_tgt]\n",
    "            tgt_causal_mask [T_tgt, T_tgt]\n",
    "            src_key_padding_mask [B, T_src]\n",
    "    outputs:\n",
    "            dec_out [B, T_tgt, d_model]\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, d_model, num_layers, num_heads, d_ff, pad_id, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, d_model, padding_idx=pad_id)\n",
    "        self.pe = PositionalEncoding(d_model, dropout=dropout)\n",
    "        self.layers = nn.ModuleList([DecoderBlock(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "\n",
    "    def forward(self, tgt_in, enc_out, tgt_key_padding_mask, tgt_causal_mask, src_key_padding_mask):\n",
    "        y = self.pe(self.emb(tgt_in))\n",
    "        for layer in self.layers:\n",
    "            y = layer(y, enc_out, tgt_key_padding_mask, tgt_causal_mask, src_key_padding_mask)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3a14bc22-63fb-4d28-a4dd-3b38e4eb185f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerSeq2Seq(nn.Module):\n",
    "    \"\"\"\n",
    "    full encode-decoder model\n",
    "    inputs (training):\n",
    "            src_ids [B, T_src]\n",
    "            tgt_in [B, T_tgt]\n",
    "            src_key_padding_mask [B, T_src]\n",
    "            tgt_key_padding_mask [B, T_tgt]\n",
    "            tgt_causal_mask [T_tgt, T_tgt]\n",
    "\n",
    "    outputs:\n",
    "            logits [B, T_tgt, V]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, d_model, num_layers, num_heads, d_ff, pad_id, dropout=0.1, tie_weights=True):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(vocab_size, d_model, num_layers, num_heads, d_ff, pad_id, dropout)\n",
    "        self.decoder = Decoder(vocab_size, d_model, num_layers, num_heads, d_ff, pad_id, dropout)\n",
    "        self.lm_head = nn.Linear(d_model, vocab_size, bias=False) #project decoder to vocab\n",
    "        if tie_weights:\n",
    "            #weights share: output layer and decoder embedding sharing the weights (common skill)\n",
    "            self.lm_head.weight = self.decoder.emb.weight\n",
    "\n",
    "    def forward(self, src_ids, tgt_in, src_key_padding_mask, tgt_key_padding_mask, tgt_causal_mask):\n",
    "        # encode a whole paragraph\n",
    "        enc_out = self.encoder(src_ids, src_key_padding_mask) #[B, T_src, d]\n",
    "\n",
    "        # decoder read in (w/ mask)\n",
    "        dec_out = self.decoder(tgt_in, enc_out, tgt_key_padding_mask, tgt_causal_mask, src_key_padding_mask) #[B, T_tgt, d]\n",
    "        \n",
    "        # project to vocab\n",
    "        logits = self.lm_head(dec_out) #[B, T_tgt, V]\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9280062e-b2f0-4026-b24e-c75837049399",
   "metadata": {},
   "source": [
    "# 5. Toy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39f7c236-eb20-4d19-bbb1-658b389670ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_toy_batch(task, batch_size, T_max, V, pad, bos, eos):\n",
    "    \"\"\"\n",
    "    构造随机小批次\n",
    "    Inputs:\n",
    "        task: 'copy' 或 'reverse'\n",
    "        batch_size: B\n",
    "        T_max: 最大源长度（每条样本真实长度随机于 [2, T_max]）\n",
    "        V: 词表大小（>= eos+1）\n",
    "        pad/bos/eos: 特殊符号 ID\n",
    "    Returns:\n",
    "        src_ids [B, T_src_max]\n",
    "        tgt_in  [B, T_tgt_max]  (BOS + target[:-1])\n",
    "        tgt_out [B, T_tgt_max]  (gold targets)\n",
    "        src_pad [B, T_src_max]  (True=PAD)\n",
    "        tgt_pad [B, T_tgt_max]  (True=PAD)\n",
    "    \"\"\"\n",
    "    assert task in {\"copy\", \"reverse\"}\n",
    "    lengths = np.random.randint(2, T_max + 1, size=batch_size)\n",
    "\n",
    "    src_list, tgt_in_list, tgt_out_list = [], [], []\n",
    "    for L in lengths:\n",
    "        # 源 token 取自 [eos+1 .. V-1]，避免与 PAD/BOS/EOS 冲突\n",
    "        src = np.random.randint(eos + 1, V, size=L).tolist()\n",
    "        if task == \"copy\":\n",
    "            tgt_core = src\n",
    "        else:\n",
    "            tgt_core = src[::-1]            # 反转任务\n",
    "\n",
    "        # 目标序列加 BOS/EOS\n",
    "        tgt = [bos] + tgt_core + [eos]\n",
    "        # teacher-forcing: 输入右移一位\n",
    "        tgt_in = tgt[:-1]\n",
    "        tgt_out = tgt[1:]\n",
    "\n",
    "        src_list.append(torch.tensor(src, dtype=torch.long))\n",
    "        tgt_in_list.append(torch.tensor(tgt_in, dtype=torch.long))\n",
    "        tgt_out_list.append(torch.tensor(tgt_out, dtype=torch.long))\n",
    "\n",
    "    # pad_sequence 统一长度，padding_value=pad\n",
    "    src_ids = nn.utils.rnn.pad_sequence(src_list, batch_first=True, padding_value=pad)\n",
    "    tgt_in  = nn.utils.rnn.pad_sequence(tgt_in_list, batch_first=True, padding_value=pad)\n",
    "    tgt_out = nn.utils.rnn.pad_sequence(tgt_out_list, batch_first=True, padding_value=pad)\n",
    "\n",
    "    # 生成 PAD 掩码（True=PAD，需要屏蔽）\n",
    "    src_pad = make_pad_mask(src_ids, pad)\n",
    "    tgt_pad = make_pad_mask(tgt_out, pad)\n",
    "    return src_ids, tgt_in, tgt_out, src_pad, tgt_pad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c52a3cb-3ebc-42c0-a2f2-f85d2a3d0c85",
   "metadata": {},
   "source": [
    "# 6. Loss, Decoding, Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0edf8e1e-f9c2-4228-abbb-20f36889819a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_ce_loss(logits, targets, pad_id, label_smoothing=0.1):\n",
    "    \"\"\"\n",
    "    cross entropy\n",
    "    inputs: logits [B, T, V], targets [B, T]\n",
    "    outputs: loss (scaler)\n",
    "    \"\"\"\n",
    "\n",
    "    B, T, V = logits.shape\n",
    "    return F.cross_entropy(logits.reshape(B*T, V), targets.reshape(B*T), ignore_index=pad_id, label_smoothing=label_smoothing, reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f94849b1-29b0-4ccf-85eb-f4ffea78ba9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def greedy_decode(model, src_ids, pad, bos, eos, max_len):\n",
    "    \"\"\"\n",
    "    greedy decode (batch)\n",
    "    Inputs:\n",
    "            src_ids [B,T_src]\n",
    "    Returns:\n",
    "            ys [B, L]（以 BOS 开头，包含 EOS 或截断）\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    B = src_ids.size(0)\n",
    "    device = src_ids.device\n",
    "\n",
    "    # 1). encoder once\n",
    "    src_key_pad = make_pad_mask(src_ids, pad).to(device) #[B, T_src]\n",
    "    enc_out = model.encoder(src_ids, src_key_pad) # [B, T_src, d]\n",
    "\n",
    "    # 2). decoder sequence from BOS to generate stepwise\n",
    "    ys = torch.full((B,1), bos, dtype=torch.long, device=device) #[B,1]\n",
    "    finished = torch.zeros(B, dtype=torch.bool, device=device) # if generate EOS\n",
    "\n",
    "    while ys.size(1) < max_len:\n",
    "        #construct tgt pad and causal pad\n",
    "        tgt_key_pad = make_pad_mask(ys, pad).to(device)             # [B,t]\n",
    "        causal = make_causal_mask(ys.size(1), device=device)        # [t,t]\n",
    "\n",
    "        # only use Decoder（already have enc_out）\n",
    "        dec_out = model.decoder(ys, enc_out, tgt_key_pad, causal, src_key_pad)  # [B,t,d]\n",
    "        logits = model.lm_head(dec_out)[:, -1, :]                    # 取最后一个位置的分布 [B,V]\n",
    "        next_ids = torch.argmax(logits, dim=-1, keepdim=True)        # 贪心选最大概率 [B,1]\n",
    "        ys = torch.cat([ys, next_ids], dim=1)                        # 追加到序列\n",
    "\n",
    "        # if all samples have generated EOS, then stop earlier\n",
    "        finished = finished | next_ids.squeeze(1).eq(eos)\n",
    "        if torch.all(finished):\n",
    "            break\n",
    "\n",
    "    return ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb2dcc6a-c4ea-43cf-9631-d749d6e070c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerLRScheduler:\n",
    "    \"\"\"\n",
    "    Transformer 经典学习率：lr = d_model^-0.5 * min(step^-0.5, step*warmup^-1.5)\n",
    "    用法：\n",
    "        sched = TransformerLRScheduler(optimizer, d_model, warmup_steps)\n",
    "        每个 step 调用 sched.step() 更新学习率\n",
    "    \"\"\"\n",
    "    def __init__(self, optimizer, d_model, warmup_steps):\n",
    "        self.optimizer = optimizer\n",
    "        self.d_model = d_model\n",
    "        self.warmup = warmup_steps\n",
    "        self.step_num = 0\n",
    "\n",
    "    def _calc_lr(self, step):\n",
    "        step = max(1, step)\n",
    "        scale = self.d_model ** (-0.5)                     # d_model^-0.5\n",
    "        return scale * min(step ** (-0.5), step * (self.warmup ** (-1.5)))\n",
    "\n",
    "    def step(self):\n",
    "        self.step_num += 1\n",
    "        lr = self._calc_lr(self.step_num)\n",
    "        for g in self.optimizer.param_groups:\n",
    "            g['lr'] = lr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb411c7-1dd1-4fdd-922a-ebc51b81c875",
   "metadata": {},
   "source": [
    "# 7. Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c8610f8-2602-48b9-8fd1-fdd4c7f285f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, scheduler, task, steps, V, T_max, pad, bos, eos,\n",
    "                grad_clip=1.0, print_every=100):\n",
    "    \"\"\"\n",
    "    合成数据上迭代 steps 次，观察 loss 下降\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    for step in range(1, steps + 1):\n",
    "        # 取一批合成数据\n",
    "        src, tgt_in, tgt_out, src_pad, tgt_pad = make_toy_batch(task, batch_size=64, T_max=T_max, V=V, pad=pad, bos=bos, eos=eos)\n",
    "        src = src.to(DEVICE); tgt_in = tgt_in.to(DEVICE); tgt_out = tgt_out.to(DEVICE)\n",
    "        src_pad = src_pad.to(DEVICE); tgt_pad = tgt_pad.to(DEVICE)\n",
    "\n",
    "        # 构造解码端因果掩码（每个 batch 的 T_tgt 可不同，这里按本批长度构造）\n",
    "        tgt_causal = make_causal_mask(tgt_in.size(1), device=DEVICE)\n",
    "\n",
    "        # 前向：teacher forcing\n",
    "        logits = model(src, tgt_in, src_pad, tgt_pad, tgt_causal)     # [B,T,V]\n",
    "        loss = seq_ce_loss(logits, tgt_out, pad_id=pad, label_smoothing=0.1)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        # 裁剪梯度防止爆炸\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "        optimizer.step()\n",
    "        scheduler.step()   # 更新学习率\n",
    "\n",
    "        if step % print_every == 0:\n",
    "            # 打印当前 loss 和 lr（便于观察 warmup 后的变化）\n",
    "            print(f\"[train step {step}/{steps}] loss={loss.item():.4f} lr={scheduler._calc_lr(scheduler.step_num):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ae063ca6-4c2a-4ed3-8cc6-2547e2d2a334",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_token_accuracy(model, task, V, T_max, pad, bos, eos, batches=20):\n",
    "    \"\"\"\n",
    "    简单 token-level 准确率（忽略 PAD）\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total, correct = 0, 0\n",
    "    for _ in range(batches):\n",
    "        src, tgt_in, tgt_out, src_pad, tgt_pad = make_toy_batch(task, batch_size=64, T_max=T_max, V=V, pad=pad, bos=bos, eos=eos)\n",
    "        src = src.to(DEVICE); tgt_in = tgt_in.to(DEVICE); tgt_out = tgt_out.to(DEVICE)\n",
    "        src_pad = src_pad.to(DEVICE); tgt_pad = tgt_pad.to(DEVICE)\n",
    "        tgt_causal = make_causal_mask(tgt_in.size(1), device=DEVICE)\n",
    "\n",
    "        logits = model(src, tgt_in, src_pad, tgt_pad, tgt_causal)     # [B,T,V]\n",
    "        pred = logits.argmax(-1)                                      # 取概率最大类 [B,T]\n",
    "        mask = ~tgt_out.eq(pad)                                       # 只统计非 PAD\n",
    "        correct += pred.eq(tgt_out).masked_select(mask).sum().item()\n",
    "        total   += mask.sum().item()\n",
    "    return correct / max(1, total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1b4958-9eb2-4769-95ed-c2f95696c679",
   "metadata": {},
   "source": [
    "# 8. Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2125e706-3086-499b-8495-1ac3e419c18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Device = mps, Task = reverse\n",
      "[train step 100/800] loss=2030475.1250 lr=0.001105\n",
      "[train step 200/800] loss=661915.6875 lr=0.002210\n",
      "[train step 300/800] loss=289922.2500 lr=0.003315\n",
      "[train step 400/800] loss=172438.4219 lr=0.004419\n",
      "[train step 500/800] loss=112699.7344 lr=0.003953\n",
      "[train step 600/800] loss=68927.2969 lr=0.003608\n",
      "[train step 700/800] loss=52565.7969 lr=0.003341\n",
      "[train step 800/800] loss=33424.7109 lr=0.003125\n",
      "[Eval] token accuracy ≈ 0.083\n",
      "\n",
      "[Greedy decode samples]\n",
      "src : [84, 126, 122, 102, 78, 188, 165, 0, 0, 0, 0]\n",
      "pred: [1, 2, 2]\n",
      "src : [196, 137, 13, 176, 135, 0, 0, 0, 0, 0, 0]\n",
      "pred: [1, 2, 2]\n",
      "src : [51, 178, 76, 17, 156, 25, 104, 195, 89, 178, 195]\n",
      "pred: [1, 68, 2]\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # ------------ 超参 ------------\n",
    "    TASK = \"reverse\"     # 'copy' 或 'reverse'\n",
    "    V = 200              # 词表大小（包含特殊符号）\n",
    "    PAD, BOS, EOS = 0, 1, 2\n",
    "    D_MODEL = 128\n",
    "    N_LAYERS = 2\n",
    "    N_HEADS = 4\n",
    "    D_FF = 4 * D_MODEL\n",
    "    DROPOUT = 0.1\n",
    "    WARMUP = 400\n",
    "    STEPS  = 800         # 可增大到 2000+ 更稳定\n",
    "    T_MAX  = 12          # 采样时的最大源长度\n",
    "\n",
    "    # ------------ 构建模型 & 优化器 ------------\n",
    "    model = TransformerSeq2Seq(\n",
    "        vocab_size=V,\n",
    "        d_model=D_MODEL,\n",
    "        num_layers=N_LAYERS,\n",
    "        num_heads=N_HEADS,\n",
    "        d_ff=D_FF,\n",
    "        pad_id=PAD,\n",
    "        dropout=DROPOUT,\n",
    "        tie_weights=True\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    # AdamW + Transformer 学习率调度\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1.0, betas=(0.9, 0.98), weight_decay=0.01)\n",
    "    scheduler = TransformerLRScheduler(optimizer, d_model=D_MODEL, warmup_steps=WARMUP)\n",
    "\n",
    "    print(f\"[Info] Device = {DEVICE}, Task = {TASK}\")\n",
    "    train_epoch(model, optimizer, scheduler, TASK, STEPS, V, T_MAX, PAD, BOS, EOS, grad_clip=1.0, print_every=100)\n",
    "\n",
    "    # ------------ 评估 ------------\n",
    "    acc = evaluate_token_accuracy(model, TASK, V, T_MAX, PAD, BOS, EOS, batches=20)\n",
    "    print(f\"[Eval] token accuracy ≈ {acc:.3f}\")\n",
    "\n",
    "    # ------------ 解码演示（贪心） ------------\n",
    "    model.eval()\n",
    "    src, tgt_in, tgt_out, _, _ = make_toy_batch(TASK, batch_size=3, T_max=T_MAX, V=V, pad=PAD, bos=BOS, eos=EOS)\n",
    "    src = src.to(DEVICE)\n",
    "    greedy = greedy_decode(model, src, PAD, BOS, EOS, max_len=T_MAX+3)\n",
    "    print(\"\\n[Greedy decode samples]\")\n",
    "    for i in range(src.size(0)):\n",
    "        print(\"src :\", src[i].tolist())\n",
    "        print(\"pred:\", greedy[i].tolist())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2c529b-2dc6-401f-9b71-bc71e5c3a81e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
